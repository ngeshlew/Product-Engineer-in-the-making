---
title: foundations (Module)
slug: modules-foundations
updated_at: "2025-08-16"
tags: [module]
---

# foundations 

> Synthesis: Transformers enable sequence modeling via attention; scaling laws and context windows drive UX constraints.

## Why itâ€™s important for designers to know
Understanding limits (context, latency) informs interaction patterns.

## How this applies to the AI-powered bot
Design prompts, retrieval, and streaming UX consistent with model limits.

## Collaboration prompts for engineers
- What context window are we budgeting for?
- What latency SLOs apply for streaming vs full responses?

## Sources
- See Sources section for LLM fundamentals, LangChain concepts, and NN/g articles

## Figures
![Transformer pipeline (concept)](../assets/concepts/transformer-pipeline.webp)
<figcaption>Credit: synthesized from multiple sources</figcaption>

