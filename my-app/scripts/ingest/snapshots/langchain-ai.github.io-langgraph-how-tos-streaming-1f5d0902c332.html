
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Build reliable, stateful AI systems, without giving up control" name="description"/>
<link href="https://langchain-ai.github.io/langgraph/how-tos/streaming/" rel="canonical"/>
<link href="../../concepts/streaming/" rel="prev"/>
<link href="../../concepts/persistence/" rel="next"/>
<link href="../../static/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.15" name="generator"/>
<title>Stream outputs</title>
<link href="../../assets/stylesheets/main.342714a4.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Public+Sans:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Public Sans";--md-code-font:"Roboto Mono"}</style>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../stylesheets/version_admonitions.css" rel="stylesheet"/>
<link href="../../stylesheets/logos.css" rel="stylesheet"/>
<link href="../../stylesheets/sticky_navigation.css" rel="stylesheet"/>
<link href="../../stylesheets/agent_graph_widget.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T35S4S46');</script>
<!-- End Google Tag Manager -->
<meta content="165B7E7C89E49946" name="algolia-site-verification">
<script>
    // Simple copy page functionality - uses original markdown source
    function copyPageAsMarkdown() {
        const markdownScript = document.getElementById('page-markdown-content');
        if (!markdownScript) {
            alert('Markdown content not available for this page');
            return;
        }
        
        try {
            let rawContent = markdownScript.textContent;
            
            // Safe HTML entity decoding function
            function decodeHtmlEntities(text) {
                const parser = new DOMParser();
                const doc = parser.parseFromString(text, 'text/html');
                return doc.documentElement.textContent || '';
            }
            
            // Always decode HTML entities since the browser might encode them
            rawContent = decodeHtmlEntities(rawContent);
            
            
            const data = JSON.parse(rawContent);
            const content = `Source: ${window.location.href}\n\n${data.markdown}`;
            
            navigator.clipboard.writeText(content).then(() => {
                // Simple notification
                const notification = document.createElement('div');
                notification.textContent = 'Page content copied to clipboard';
                notification.style.cssText = 'position:fixed;top:20px;right:20px;background:#4CAF50;color:white;padding:10px 16px;border-radius:4px;z-index:9999;box-shadow:0 2px 10px rgba(0,0,0,0.2);';
                document.body.appendChild(notification);
                setTimeout(() => notification.remove(), 3000);
            }).catch(() => {
                alert('Failed to copy content');
            });
        } catch (e) {
            console.error('Failed to parse page content:', e);
            alert('Failed to parse page content: ' + e.message);
        }
    }

    // Add dropdown button to header when page loads
    document.addEventListener('DOMContentLoaded', function() {
        const headerSource = document.querySelector('.md-header__source');
        if (headerSource) {
            // Create dropdown container
            const dropdownContainer = document.createElement('div');
            dropdownContainer.style.cssText = 'position:relative;display:inline-block;margin-left:8px;';
            
            // Create main button
            const button = document.createElement('button');
            button.innerHTML = 'Copy page <span style="margin-left:8px;font-size:12px;color:#9ca3af;">▾</span>';
            button.style.cssText = 'background:transparent;border:1px solid #d1d5db;padding:6px 12px;border-radius:4px;cursor:pointer;font-size:14px;color:#374151;transition:all 0.2s ease;white-space:nowrap;display:flex;align-items:center;';
            
            // Create dropdown menu
            const dropdown = document.createElement('div');
            dropdown.className = 'copy-page-dropdown';
            dropdown.style.cssText = 'position:absolute;top:100%;left:0;background:white;border:1px solid #e5e7eb;border-radius:6px;box-shadow:0 4px 12px rgba(0,0,0,0.15);z-index:1000;min-width:180px;display:none;padding:4px 0;';
            
            // Create dropdown options
            const option1 = document.createElement('div');
            option1.textContent = 'Copy as Markdown for LLMs';
            option1.className = 'copy-page-option';
            option1.style.cssText = 'padding:8px 16px;cursor:pointer;font-size:14px;color:#374151;margin:2px 0;';
            option1.onmouseover = function() { 
                this.style.background = document.documentElement.getAttribute('data-md-color-scheme') === 'slate' ? '#4a5568' : '#f8fafc'; 
            };
            option1.onmouseout = function() { this.style.background = 'transparent'; };
            option1.onclick = function() {
                // Check if we're on a reference page
                if (window.location.pathname.includes('/reference/')) {
                    alert('Copy Page not yet available in API reference pages.');
                } else {
                    copyPageAsMarkdown();
                }
                dropdown.style.display = 'none';
            };
            
            const option2 = document.createElement('div');
            option2.textContent = "View LangGraph's llms.txt";
            option2.className = 'copy-page-option';
            option2.style.cssText = 'padding:8px 16px;cursor:pointer;font-size:14px;color:#374151;margin:2px 0;';
            option2.onmouseover = function() { 
                this.style.background = document.documentElement.getAttribute('data-md-color-scheme') === 'slate' ? '#4a5568' : '#f8fafc'; 
            };
            option2.onmouseout = function() { this.style.background = 'transparent'; };
            option2.onclick = function() {
                window.open('/langgraph/llms-txt-overview/', '_blank');
                dropdown.style.display = 'none';
            };
            
            // Add options to dropdown
            dropdown.appendChild(option1);
            dropdown.appendChild(option2);
            
            // Button hover effects
            button.onmouseover = function() { 
                this.style.background = '#f3f4f6'; 
                this.style.borderColor = '#9ca3af'; 
            };
            button.onmouseout = function() { 
                this.style.background = 'transparent'; 
                this.style.borderColor = '#d1d5db'; 
            };
            
            // Toggle dropdown
            button.onclick = function(e) {
                e.stopPropagation();
                dropdown.style.display = dropdown.style.display === 'none' ? 'block' : 'none';
            };
            
            // Close dropdown when clicking outside
            document.addEventListener('click', function() {
                dropdown.style.display = 'none';
            });
            
            // Assemble dropdown
            dropdownContainer.appendChild(button);
            dropdownContainer.appendChild(dropdown);
            headerSource.parentNode.insertBefore(dropdownContainer, headerSource.nextSibling);
        }
    });
  </script>
<style>
    @import url("https://fonts.googleapis.com/css2?family=Public+Sans&display=swap");
    :root {
      --md-primary-fg-color: #333333;
      --md-accent-fg-color: #1E88E5;
      --md-default-bg-color: #FFFFFF;
      --md-default-fg-color: #333333;
      --md-text-font-family: "Public Sans", sans-serif;
    }

    body {
      font-family: var(--md-text-font-family);
      background-color: var(--md-default-bg-color);
      color: var(--md-default-fg-color);
    }

    .md-main {
      background-color: #FFFFFF;
    }

    .md-footer {
      background-color: #F5F5F5;
      color: #666666;
    }

    .md-footer-meta {
      background-color: #4d4d4d;
    }

    .md-typeset a {
      color: #1E88E5;
    }

    .md-typeset a:hover {
      color: #1565C0;
    }

    .md-nav__link--active,
    .md-nav__link:active {
      color: #1E88E5;
    }

    .md-search__input {
      background-color: #F5F5F5;
      color: #333333;
    }

    .md-search__input:hover,
    .md-search__input:focus {
      background-color: #EEEEEE;
    }
    /* Table of contents styles */
    .md-nav--secondary .md-nav__item--active > .md-nav__link {
      font-weight: bold;
      color: var(--md-primary-fg-color);
    }

    .md-nav--secondary .md-nav__item--nested > .md-nav__link {
      font-weight: normal;
      color: var(--md-default-fg-color);
    }

    .md-nav--secondary .md-nav__item--nested > .md-nav__link::before {
      content: "";
      display: inline-block;
      width: 6px;
      height: 6px;
      background-color: var(--md-default-fg-color);
      border-radius: 50%;
      margin-right: 0.5rem;
    }

    [data-md-color-scheme="slate"] {
      --md-default-bg-color: #1E1E1E;
      --md-default-fg-color: #FFFFFF;
      --md-accent-fg-color: #64B5F6;
    }

    [data-md-color-scheme="slate"] .md-main {
      background-color: #1E1E1E;
    }

    [data-md-color-scheme="slate"] .navbar {
      background-color: #1E1E1E;
      color: #FFFFFF;
      box-shadow: none;
    }

    [data-md-color-scheme="slate"] .md-footer {
      background-color: #1E1E1E;
      color: #BDBDBD;
    }

    [data-md-color-scheme="slate"] .md-header {
      background-color: #1E1E1E;
      color: #BDBDBD;
    }

    [data-md-color-scheme="slate"] .md-tabs {
      background-color: #1E1E1E;
      color: #BDBDBD;
    }

    [data-md-color-scheme="slate"] .md-search__input {
      background-color: #F5F5F5;
      color: #333333;
    }

    [data-md-color-scheme="slate"] .md-search__icon {
      color: #333333;
    }

    [data-md-color-scheme="slate"] .md-search__input::placeholder {
      color: #333333;
    }

    [data-md-color-scheme="slate"] .md-footer-meta {
      background-color: #4d4d4d;
    }

    [data-md-color-scheme="slate"] .md-typeset a {
      color: #64B5F6;
    }

    [data-md-color-scheme="slate"] .md-typeset a:hover {
      color: #90CAF9;
    }

    .notebook-links {
      display: flex;
      justify-content: flex-end;
      margin-bottom: 1rem;
    }
    .notebook-links .md-content__button {
      margin-left: 0.5rem;
    }

    [data-md-color-scheme=default] .logo-dark {
      display: none !important;
    }

    [data-md-color-scheme=slate] .logo-light {
      display: none !important;
    }

    .jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt.jp-InputArea-prompt {
      display: none !important;
    }

    .jupyter-wrapper .jp-Notebook .jp-Cell .jp-OutputPrompt {
      display: none !important;
    }

    .md-banner {
      background-color: #CFC9FA;
      color: #000000;
    }

    .md-banner a {
      color: #000000;
      text-decoration: underline;
    }

    .md-banner a:hover {
      color: #000000;
    }

    .md-header__title {
      visibility: hidden;
    }

    /* Dark mode banner styling */
    [data-md-color-scheme="slate"] .md-banner {
      background-color: #CFC9FA; /* Same light purple for both modes */
      color: #000000;
    }

    [data-md-color-scheme="slate"] .md-banner a {
      color: #000000;
    }

    [data-md-color-scheme="slate"] .md-banner a:hover {
      color: #000000;
    }

    /* Copy page dropdown dark mode support */
    [data-md-color-scheme="slate"] .copy-page-dropdown {
      background: #1f2937 !important;
      border-color: #374151 !important;
      box-shadow: 0 4px 12px rgba(0,0,0,0.5) !important;
    }

    [data-md-color-scheme="slate"] .copy-page-option {
      color: #e5e7eb !important;
    }

  </style>
<script id="page-markdown-content" type="application/json">{"markdown": "# Stream outputs\n\nYou can [stream outputs](../concepts/streaming.md) from a LangGraph agent or workflow.\n\n## Supported stream modes\n\nPass one or more of the following stream modes as a list to the [`stream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.stream) or [`astream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.astream) methods:\n\n\n\n\n| Mode       | Description                                                                                                                                                                         |\n| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `values`   | Streams the full value of the state after each step of the graph.                                                                                                                   |\n| `updates`  | Streams the updates to the state after each step of the graph. If multiple updates are made in the same step (e.g., multiple nodes are run), those updates are streamed separately. |\n| `custom`   | Streams custom data from inside your graph nodes.                                                                                                                                   |\n| `messages` | Streams 2-tuples (LLM token, metadata) from any graph nodes where an LLM is invoked.                                                                                                |\n| `debug`    | Streams as much information as possible throughout the execution of the graph.                                                                                                      |\n\n## Stream from an agent\n\n### Agent progress\n\nTo stream agent progress, use the [`stream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.stream) or [`astream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.astream) methods with `stream_mode=\"updates\"`. This emits an event after every agent step.\n\n\n\n\nFor example, if you have an agent that calls a tool once, you should see the following updates:\n\n- **LLM node**: AI message with tool call requests\n- **Tool node**: Tool message with execution result\n- **LLM node**: Final AI response\n\n=== \"Sync\"\n\n    ```python hl_lines=\"5 7\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"updates\"\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n=== \"Async\"\n\n    ```python hl_lines=\"5 7\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n    async for chunk in agent.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"updates\"\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n\n\n\n\n### LLM tokens\n\nTo stream tokens as they are produced by the LLM, use `stream_mode=\"messages\"`:\n\n=== \"Sync\"\n\n    ```python hl_lines=\"5 7\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n    for token, metadata in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"messages\"\n    ):\n        print(\"Token\", token)\n        print(\"Metadata\", metadata)\n        print(\"\\n\")\n    ```\n\n=== \"Async\"\n\n    ```python hl_lines=\"5 7\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n    async for token, metadata in agent.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"messages\"\n    ):\n        print(\"Token\", token)\n        print(\"Metadata\", metadata)\n        print(\"\\n\")\n    ```\n\n\n\n\n\n### Tool updates\n\nTo stream updates from tools as they are executed, you can use [get_stream_writer](https://langchain-ai.github.io/langgraph/reference/config/#langgraph.config.get_stream_writer).\n\n=== \"Sync\"\n\n    ```python hl_lines=\"1 5 7 17\"\n    from langgraph.config import get_stream_writer\n\n    def get_weather(city: str) -> str:\n        \"\"\"Get weather for a given city.\"\"\"\n        writer = get_stream_writer()\n        # stream any arbitrary data\n        writer(f\"Looking up data for city: {city}\")\n        return f\"It's always sunny in {city}!\"\n\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n\n    for chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"custom\"\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n=== \"Async\"\n\n    ```python hl_lines=\"1 5 7 17\"\n    from langgraph.config import get_stream_writer\n\n    def get_weather(city: str) -> str:\n        \"\"\"Get weather for a given city.\"\"\"\n        writer = get_stream_writer()\n        # stream any arbitrary data\n        writer(f\"Looking up data for city: {city}\")\n        return f\"It's always sunny in {city}!\"\n\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n\n    async for chunk in agent.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=\"custom\"\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n!!! Note\n\n      If you add `get_stream_writer` inside your tool, you won't be able to invoke the tool outside of a LangGraph execution context.\n\n\n\n\n\n### Stream multiple modes\n\nYou can specify multiple streaming modes by passing stream mode as a list: `stream_mode=[\"updates\", \"messages\", \"custom\"]`:\n\n=== \"Sync\"\n\n    ```python hl_lines=\"8\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n\n    for stream_mode, chunk in agent.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=[\"updates\", \"messages\", \"custom\"]\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n=== \"Async\"\n\n    ```python hl_lines=\"8\"\n    agent = create_react_agent(\n        model=\"anthropic:claude-3-7-sonnet-latest\",\n        tools=[get_weather],\n    )\n\n    async for stream_mode, chunk in agent.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n        stream_mode=[\"updates\", \"messages\", \"custom\"]\n    ):\n        print(chunk)\n        print(\"\\n\")\n    ```\n\n\n\n\n\n### Disable streaming\n\nIn some applications you might need to disable streaming of individual tokens for a given model. This is useful in [multi-agent](../agents/multi-agent.md) systems to control which agents stream their output.\n\nSee the [Models](../agents/models.md#disable-streaming) guide to learn how to disable streaming.\n\n## Stream from a workflow\n\n### Basic usage example\n\nLangGraph graphs expose the [`.stream()`](https://langchain-ai.github.io/langgraph/reference/pregel/#langgraph.pregel.Pregel.stream) (sync) and [`.astream()`](https://langchain-ai.github.io/langgraph/reference/pregel/#langgraph.pregel.Pregel.astream) (async) methods to yield streamed outputs as iterators.\n\n=== \"Sync\"\n\n    ```python\n    for chunk in graph.stream(inputs, stream_mode=\"updates\"):\n        print(chunk)\n    ```\n\n=== \"Async\"\n\n    ```python\n    async for chunk in graph.astream(inputs, stream_mode=\"updates\"):\n        print(chunk)\n    ```\n\n\n\n\n\n??? example \"Extended example: streaming updates\"\n\n      ```python hl_lines=\"24 26\"\n      from typing import TypedDict\n      from langgraph.graph import StateGraph, START, END\n\n      class State(TypedDict):\n          topic: str\n          joke: str\n\n      def refine_topic(state: State):\n          return {\"topic\": state[\"topic\"] + \" and cats\"}\n\n      def generate_joke(state: State):\n          return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\n      graph = (\n          StateGraph(State)\n          .add_node(refine_topic)\n          .add_node(generate_joke)\n          .add_edge(START, \"refine_topic\")\n          .add_edge(\"refine_topic\", \"generate_joke\")\n          .add_edge(\"generate_joke\", END)\n          .compile()\n      )\n\n      for chunk in graph.stream( # (1)!\n          {\"topic\": \"ice cream\"},\n          stream_mode=\"updates\", # (2)!\n      ):\n          print(chunk)\n      ```\n\n      1. The `stream()` method returns an iterator that yields streamed outputs.\n      2. Set `stream_mode=\"updates\"` to stream only the updates to the graph state after each node. Other stream modes are also available. See [supported stream modes](#supported-stream-modes) for details.\n\n\n\n\n      ```output\n      {'refineTopic': {'topic': 'ice cream and cats'}}\n      {'generateJoke': {'joke': 'This is a joke about ice cream and cats'}}\n      ```                                                                                                   |\n\n### Stream multiple modes\n\nYou can pass a list as the `stream_mode` parameter to stream multiple modes at once.\n\nThe streamed outputs will be tuples of `(mode, chunk)` where `mode` is the name of the stream mode and `chunk` is the data streamed by that mode.\n\n=== \"Sync\"\n\n    ```python\n    for mode, chunk in graph.stream(inputs, stream_mode=[\"updates\", \"custom\"]):\n        print(chunk)\n    ```\n\n=== \"Async\"\n\n    ```python\n    async for mode, chunk in graph.astream(inputs, stream_mode=[\"updates\", \"custom\"]):\n        print(chunk)\n    ```\n\n\n\n\n\n### Stream graph state\n\nUse the stream modes `updates` and `values` to stream the state of the graph as it executes.\n\n- `updates` streams the **updates** to the state after each step of the graph.\n- `values` streams the **full value** of the state after each step of the graph.\n\n<sup><i>API Reference: <a href=\"https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph\">StateGraph\u003c/a> | <a href=\"https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START\">START\u003c/a> | <a href=\"https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.END\">END\u003c/a>\u003c/i>\u003c/sup>\n\n```python\nfrom typing import TypedDict\nfrom langgraph.graph import StateGraph, START, END\n\n\nclass State(TypedDict):\n  topic: str\n  joke: str\n\n\ndef refine_topic(state: State):\n    return {\"topic\": state[\"topic\"] + \" and cats\"}\n\n\ndef generate_joke(state: State):\n    return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\ngraph = (\n  StateGraph(State)\n  .add_node(refine_topic)\n  .add_node(generate_joke)\n  .add_edge(START, \"refine_topic\")\n  .add_edge(\"refine_topic\", \"generate_joke\")\n  .add_edge(\"generate_joke\", END)\n  .compile()\n)\n```\n\n\n\n\n\n=== \"updates\"\n\n    Use this to stream only the **state updates** returned by the nodes after each step. The streamed outputs include the name of the node as well as the update.\n\n    ```python hl_lines=\"3\"\n    for chunk in graph.stream(\n        {\"topic\": \"ice cream\"},\n        stream_mode=\"updates\",\n    ):\n        print(chunk)\n    ```\n\n\n\n\n=== \"values\"\n\n    Use this to stream the **full state** of the graph after each step.\n\n    ```python hl_lines=\"3\"\n    for chunk in graph.stream(\n        {\"topic\": \"ice cream\"},\n        stream_mode=\"values\",\n    ):\n        print(chunk)\n    ```\n\n\n\n\n### Stream subgraph outputs\n\nTo include outputs from [subgraphs](../concepts/subgraphs.md) in the streamed outputs, you can set `subgraphs=True` in the `.stream()` method of the parent graph. This will stream outputs from both the parent graph and any subgraphs.\n\nThe outputs will be streamed as tuples `(namespace, data)`, where `namespace` is a tuple with the path to the node where a subgraph is invoked, e.g. `(\"parent_node:<task_id>\", \"child_node:<task_id>\")`.\n\n```python hl_lines=\"3\"\nfor chunk in graph.stream(\n    {\"foo\": \"foo\"},\n    subgraphs=True, # (1)!\n    stream_mode=\"updates\",\n):\n    print(chunk)\n```\n\n1. Set `subgraphs=True` to stream outputs from subgraphs.\n\n\n\n\n??? example \"Extended example: streaming from subgraphs\"\n\n      ```python hl_lines=\"39\"\n      from langgraph.graph import START, StateGraph\n      from typing import TypedDict\n\n      # Define subgraph\n      class SubgraphState(TypedDict):\n          foo: str  # note that this key is shared with the parent graph state\n          bar: str\n\n      def subgraph_node_1(state: SubgraphState):\n          return {\"bar\": \"bar\"}\n\n      def subgraph_node_2(state: SubgraphState):\n          return {\"foo\": state[\"foo\"] + state[\"bar\"]}\n\n      subgraph_builder = StateGraph(SubgraphState)\n      subgraph_builder.add_node(subgraph_node_1)\n      subgraph_builder.add_node(subgraph_node_2)\n      subgraph_builder.add_edge(START, \"subgraph_node_1\")\n      subgraph_builder.add_edge(\"subgraph_node_1\", \"subgraph_node_2\")\n      subgraph = subgraph_builder.compile()\n\n      # Define parent graph\n      class ParentState(TypedDict):\n          foo: str\n\n      def node_1(state: ParentState):\n          return {\"foo\": \"hi! \" + state[\"foo\"]}\n\n      builder = StateGraph(ParentState)\n      builder.add_node(\"node_1\", node_1)\n      builder.add_node(\"node_2\", subgraph)\n      builder.add_edge(START, \"node_1\")\n      builder.add_edge(\"node_1\", \"node_2\")\n      graph = builder.compile()\n\n      for chunk in graph.stream(\n          {\"foo\": \"foo\"},\n          stream_mode=\"updates\",\n          subgraphs=True, # (1)!\n      ):\n          print(chunk)\n      ```\n\n      1. Set `subgraphs=True` to stream outputs from subgraphs.\n\n\n\n\n      ```\n      ((), {'node_1': {'foo': 'hi! foo'}})\n      (('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_1': {'bar': 'bar'}})\n      (('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_2': {'foo': 'hi! foobar'}})\n      ((), {'node_2': {'foo': 'hi! foobar'}})\n      ```\n\n\n\n\n      **Note** that we are receiving not just the node updates, but we also the namespaces which tell us what graph (or subgraph) we are streaming from.\n\n### Debugging {#debug}\n\nUse the `debug` streaming mode to stream as much information as possible throughout the execution of the graph. The streamed outputs include the name of the node as well as the full state.\n\n```python hl_lines=\"3\"\nfor chunk in graph.stream(\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"debug\",\n):\n    print(chunk)\n```\n\n\n\n\n\n### LLM tokens {#messages}\n\nUse the `messages` streaming mode to stream Large Language Model (LLM) outputs **token by token** from any part of your graph, including nodes, tools, subgraphs, or tasks.\n\nThe streamed output from [`messages` mode](#supported-stream-modes) is a tuple `(message_chunk, metadata)` where:\n\n- `message_chunk`: the token or message segment from the LLM.\n- `metadata`: a dictionary containing details about the graph node and LLM invocation.\n\n> If your LLM is not available as a LangChain integration, you can stream its outputs using `custom` mode instead. See [use with any LLM](#use-with-any-llm) for details.\n\n!!! warning \"Manual config required for async in Python < 3.11\"\n\n    When using Python < 3.11 with async code, you must explicitly pass `RunnableConfig` to `ainvoke()` to enable proper streaming. See [Async with Python < 3.11](#async) for details or upgrade to Python 3.11+.\n\n<sup><i>API Reference: <a href=\"https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html\">init_chat_model\u003c/a> | <a href=\"https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph\">StateGraph\u003c/a> | <a href=\"https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START\">START\u003c/a>\u003c/i>\u003c/sup>\n\n```python hl_lines=\"17 33\"\nfrom dataclasses import dataclass\n\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, START\n\n\n@dataclass\nclass MyState:\n    topic: str\n    joke: str = \"\"\n\n\nllm = init_chat_model(model=\"openai:gpt-4o-mini\")\n\ndef call_model(state: MyState):\n    \"\"\"Call the LLM to generate a joke about a topic\"\"\"\n    llm_response = llm.invoke( # (1)!\n        [\n            {\"role\": \"user\", \"content\": f\"Generate a joke about {state.topic}\"}\n        ]\n    )\n    return {\"joke\": llm_response.content}\n\ngraph = (\n    StateGraph(MyState)\n    .add_node(call_model)\n    .add_edge(START, \"call_model\")\n    .compile()\n)\n\nfor message_chunk, metadata in graph.stream( # (2)!\n    {\"topic\": \"ice cream\"},\n    stream_mode=\"messages\",\n):\n    if message_chunk.content:\n        print(message_chunk.content, end=\"|\", flush=True)\n```\n\n1. Note that the message events are emitted even when the LLM is run using `.invoke` rather than `.stream`.\n2. The \"messages\" stream mode returns an iterator of tuples `(message_chunk, metadata)` where `message_chunk` is the token streamed by the LLM and `metadata` is a dictionary with information about the graph node where the LLM was called and other information.\n\n\n\n\n#### Filter by LLM invocation\n\nYou can associate `tags` with LLM invocations to filter the streamed tokens by LLM invocation.\n\n<sup><i>API Reference: <a href=\"https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html\">init_chat_model\u003c/a>\u003c/i>\u003c/sup>\n\n```python hl_lines=\"10\"\nfrom langchain.chat_models import init_chat_model\n\nllm_1 = init_chat_model(model=\"openai:gpt-4o-mini\", tags=['joke']) # (1)!\nllm_2 = init_chat_model(model=\"openai:gpt-4o-mini\", tags=['poem']) # (2)!\n\ngraph = ... # define a graph that uses these LLMs\n\nasync for msg, metadata in graph.astream(  # (3)!\n    {\"topic\": \"cats\"},\n    stream_mode=\"messages\",\n):\n    if metadata[\"tags\"] == [\"joke\"]: # (4)!\n        print(msg.content, end=\"|\", flush=True)\n```\n\n1. llm_1 is tagged with \"joke\".\n2. llm_2 is tagged with \"poem\".\n3. The `stream_mode` is set to \"messages\" to stream LLM tokens. The `metadata` contains information about the LLM invocation, including the tags.\n4. Filter the streamed tokens by the `tags` field in the metadata to only include the tokens from the LLM invocation with the \"joke\" tag.\n\n\n\n\n??? example \"Extended example: filtering by tags\"\n\n      ```python hl_lines=\"42\"\n      from typing import TypedDict\n\n      from langchain.chat_models import init_chat_model\n      from langgraph.graph import START, StateGraph\n\n      joke_model = init_chat_model(model=\"openai:gpt-4o-mini\", tags=[\"joke\"]) # (1)!\n      poem_model = init_chat_model(model=\"openai:gpt-4o-mini\", tags=[\"poem\"]) # (2)!\n\n\n      class State(TypedDict):\n            topic: str\n            joke: str\n            poem: str\n\n\n      async def call_model(state, config):\n            topic = state[\"topic\"]\n            print(\"Writing joke...\")\n            # Note: Passing the config through explicitly is required for python < 3.11\n            # Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks\n            joke_response = await joke_model.ainvoke(\n                  [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n                  config, # (3)!\n            )\n            print(\"\\n\\nWriting poem...\")\n            poem_response = await poem_model.ainvoke(\n                  [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}],\n                  config, # (3)!\n            )\n            return {\"joke\": joke_response.content, \"poem\": poem_response.content}\n\n\n      graph = (\n            StateGraph(State)\n            .add_node(call_model)\n            .add_edge(START, \"call_model\")\n            .compile()\n      )\n\n      async for msg, metadata in graph.astream(\n            {\"topic\": \"cats\"},\n            stream_mode=\"messages\", # (4)!\n      ):\n          if metadata[\"tags\"] == [\"joke\"]: # (4)!\n              print(msg.content, end=\"|\", flush=True)\n      ```\n\n      1. The `joke_model` is tagged with \"joke\".\n      2. The `poem_model` is tagged with \"poem\".\n      3. The `config` is passed through explicitly to ensure the context vars are propagated correctly. This is required for Python < 3.11 when using async code. Please see the [async section](#async) for more details.\n      4. The `stream_mode` is set to \"messages\" to stream LLM tokens. The `metadata` contains information about the LLM invocation, including the tags.\n\n\n\n\n#### Filter by node\n\nTo stream tokens only from specific nodes, use `stream_mode=\"messages\"` and filter the outputs by the `langgraph_node` field in the streamed metadata:\n\n```python hl_lines=\"3 5\"\nfor msg, metadata in graph.stream( # (1)!\n    inputs,\n    stream_mode=\"messages\",\n):\n    if msg.content and metadata[\"langgraph_node\"] == \"some_node_name\": # (2)!\n        ...\n```\n\n1. The \"messages\" stream mode returns a tuple of `(message_chunk, metadata)` where `message_chunk` is the token streamed by the LLM and `metadata` is a dictionary with information about the graph node where the LLM was called and other information.\n2. Filter the streamed tokens by the `langgraph_node` field in the metadata to only include the tokens from the `write_poem` node.\n\n\n\n\n??? example \"Extended example: streaming LLM tokens from specific nodes\"\n\n      ```python hl_lines=\"40 44\"\n      from typing import TypedDict\n      from langgraph.graph import START, StateGraph\n      from langchain_openai import ChatOpenAI\n\n      model = ChatOpenAI(model=\"gpt-4o-mini\")\n\n\n      class State(TypedDict):\n            topic: str\n            joke: str\n            poem: str\n\n\n      def write_joke(state: State):\n            topic = state[\"topic\"]\n            joke_response = model.invoke(\n                  [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}]\n            )\n            return {\"joke\": joke_response.content}\n\n\n      def write_poem(state: State):\n            topic = state[\"topic\"]\n            poem_response = model.invoke(\n                  [{\"role\": \"user\", \"content\": f\"Write a short poem about {topic}\"}]\n            )\n            return {\"poem\": poem_response.content}\n\n\n      graph = (\n            StateGraph(State)\n            .add_node(write_joke)\n            .add_node(write_poem)\n            # write both the joke and the poem concurrently\n            .add_edge(START, \"write_joke\")\n            .add_edge(START, \"write_poem\")\n            .compile()\n      )\n\n      for msg, metadata in graph.stream( # (1)!\n          {\"topic\": \"cats\"},\n          stream_mode=\"messages\",\n      ):\n          if msg.content and metadata[\"langgraph_node\"] == \"write_poem\": # (2)!\n              print(msg.content, end=\"|\", flush=True)\n      ```\n\n      1. The \"messages\" stream mode returns a tuple of `(message_chunk, metadata)` where `message_chunk` is the token streamed by the LLM and `metadata` is a dictionary with information about the graph node where the LLM was called and other information.\n      2. Filter the streamed tokens by the `langgraph_node` field in the metadata to only include the tokens from the `write_poem` node.\n\n\n\n\n### Stream custom data\n\nTo send **custom user-defined data** from inside a LangGraph node or tool, follow these steps:\n\n1. Use `get_stream_writer()` to access the stream writer and emit custom data.\n2. Set `stream_mode=\"custom\"` when calling `.stream()` or `.astream()` to get the custom data in the stream. You can combine multiple modes (e.g., `[\"updates\", \"custom\"]`), but at least one must be `\"custom\"`.\n\n!!! warning \"No `get_stream_writer()` in async for Python < 3.11\"\n\n    In async code running on Python < 3.11, `get_stream_writer()` will not work.\n    Instead, add a `writer` parameter to your node or tool and pass it manually.\n    See [Async with Python < 3.11](#async) for usage examples.\n\n=== \"node\"\n\n      ```python\n      from typing import TypedDict\n      from langgraph.config import get_stream_writer\n      from langgraph.graph import StateGraph, START\n\n      class State(TypedDict):\n          query: str\n          answer: str\n\n      def node(state: State):\n          writer = get_stream_writer()  # (1)!\n          writer({\"custom_key\": \"Generating custom data inside node\"}) # (2)!\n          return {\"answer\": \"some data\"}\n\n      graph = (\n          StateGraph(State)\n          .add_node(node)\n          .add_edge(START, \"node\")\n          .compile()\n      )\n\n      inputs = {\"query\": \"example\"}\n\n      # Usage\n      for chunk in graph.stream(inputs, stream_mode=\"custom\"):  # (3)!\n          print(chunk)\n      ```\n\n      1. Get the stream writer to send custom data.\n      2. Emit a custom key-value pair (e.g., progress update).\n      3. Set `stream_mode=\"custom\"` to receive the custom data in the stream.\n\n=== \"tool\"\n\n      ```python hl_lines=\"8 10\"\n      from langchain_core.tools import tool\n      from langgraph.config import get_stream_writer\n\n      @tool\n      def query_database(query: str) -> str:\n          \"\"\"Query the database.\"\"\"\n          writer = get_stream_writer() # (1)!\n          writer({\"data\": \"Retrieved 0/100 records\", \"type\": \"progress\"}) # (2)!\n          # perform query\n          writer({\"data\": \"Retrieved 100/100 records\", \"type\": \"progress\"}) # (3)!\n          return \"some-answer\"\n\n\n      graph = ... # define a graph that uses this tool\n\n      for chunk in graph.stream(inputs, stream_mode=\"custom\"): # (4)!\n          print(chunk)\n      ```\n\n      1. Access the stream writer to send custom data.\n      2. Emit a custom key-value pair (e.g., progress update).\n      3. Emit another custom key-value pair.\n      4. Set `stream_mode=\"custom\"` to receive the custom data in the stream.\n\n\n\n\n\n### Use with any LLM\n\nYou can use `stream_mode=\"custom\"` to stream data from **any LLM API** — even if that API does **not** implement the LangChain chat model interface.\n\nThis lets you integrate raw LLM clients or external services that provide their own streaming interfaces, making LangGraph highly flexible for custom setups.\n\n<sup><i>API Reference: <a href=\"https://langchain-ai.github.io/langgraph/reference/config/#langgraph.config.get_stream_writer\">get_stream_writer\u003c/a>\u003c/i>\u003c/sup>\n\n```python hl_lines=\"5 8 20\"\nfrom langgraph.config import get_stream_writer\n\ndef call_arbitrary_model(state):\n    \"\"\"Example node that calls an arbitrary model and streams the output\"\"\"\n    writer = get_stream_writer() # (1)!\n    # Assume you have a streaming client that yields chunks\n    for chunk in your_custom_streaming_client(state[\"topic\"]): # (2)!\n        writer({\"custom_llm_chunk\": chunk}) # (3)!\n    return {\"result\": \"completed\"}\n\ngraph = (\n    StateGraph(State)\n    .add_node(call_arbitrary_model)\n    # Add other nodes and edges as needed\n    .compile()\n)\n\nfor chunk in graph.stream(\n    {\"topic\": \"cats\"},\n    stream_mode=\"custom\", # (4)!\n):\n    # The chunk will contain the custom data streamed from the llm\n    print(chunk)\n```\n\n1. Get the stream writer to send custom data.\n2. Generate LLM tokens using your custom streaming client.\n3. Use the writer to send custom data to the stream.\n4. Set `stream_mode=\"custom\"` to receive the custom data in the stream.\n\n\n\n\n??? example \"Extended example: streaming arbitrary chat model\"\n\n      ```python\n      import operator\n      import json\n\n      from typing import TypedDict\n      from typing_extensions import Annotated\n      from langgraph.graph import StateGraph, START\n\n      from openai import AsyncOpenAI\n\n      openai_client = AsyncOpenAI()\n      model_name = \"gpt-4o-mini\"\n\n\n      async def stream_tokens(model_name: str, messages: list[dict]):\n          response = await openai_client.chat.completions.create(\n              messages=messages, model=model_name, stream=True\n          )\n          role = None\n          async for chunk in response:\n              delta = chunk.choices[0].delta\n\n              if delta.role is not None:\n                  role = delta.role\n\n              if delta.content:\n                  yield {\"role\": role, \"content\": delta.content}\n\n\n      # this is our tool\n      async def get_items(place: str) -> str:\n          \"\"\"Use this tool to list items one might find in a place you're asked about.\"\"\"\n          writer = get_stream_writer()\n          response = \"\"\n          async for msg_chunk in stream_tokens(\n              model_name,\n              [\n                  {\n                      \"role\": \"user\",\n                      \"content\": (\n                          \"Can you tell me what kind of items \"\n                          f\"i might find in the following place: '{place}'. \"\n                          \"List at least 3 such items separating them by a comma. \"\n                          \"And include a brief description of each item.\"\n                      ),\n                  }\n              ],\n          ):\n              response += msg_chunk[\"content\"]\n              writer(msg_chunk)\n\n          return response\n\n\n      class State(TypedDict):\n          messages: Annotated[list[dict], operator.add]\n\n\n      # this is the tool-calling graph node\n      async def call_tool(state: State):\n          ai_message = state[\"messages\"][-1]\n          tool_call = ai_message[\"tool_calls\"][-1]\n\n          function_name = tool_call[\"function\"][\"name\"]\n          if function_name != \"get_items\":\n              raise ValueError(f\"Tool {function_name} not supported\")\n\n          function_arguments = tool_call[\"function\"][\"arguments\"]\n          arguments = json.loads(function_arguments)\n\n          function_response = await get_items(**arguments)\n          tool_message = {\n              \"tool_call_id\": tool_call[\"id\"],\n              \"role\": \"tool\",\n              \"name\": function_name,\n              \"content\": function_response,\n          }\n          return {\"messages\": [tool_message]}\n\n\n      graph = (\n          StateGraph(State)\n          .add_node(call_tool)\n          .add_edge(START, \"call_tool\")\n          .compile()\n      )\n      ```\n\n      Let's invoke the graph with an AI message that includes a tool call:\n\n      ```python\n      inputs = {\n          \"messages\": [\n              {\n                  \"content\": None,\n                  \"role\": \"assistant\",\n                  \"tool_calls\": [\n                      {\n                          \"id\": \"1\",\n                          \"function\": {\n                              \"arguments\": '{\"place\":\"bedroom\"}',\n                              \"name\": \"get_items\",\n                          },\n                          \"type\": \"function\",\n                      }\n                  ],\n              }\n          ]\n      }\n\n      async for chunk in graph.astream(\n          inputs,\n          stream_mode=\"custom\",\n      ):\n          print(chunk[\"content\"], end=\"|\", flush=True)\n      ```\n\n\n\n\n### Disable streaming for specific chat models\n\nIf your application mixes models that support streaming with those that do not, you may need to explicitly disable streaming for\nmodels that do not support it.\n\nSet `disable_streaming=True` when initializing the model.\n\n=== \"init_chat_model\"\n\n      ```python hl_lines=\"5\"\n      from langchain.chat_models import init_chat_model\n\n      model = init_chat_model(\n          \"anthropic:claude-3-7-sonnet-latest\",\n          disable_streaming=True # (1)!\n      )\n      ```\n\n      1. Set `disable_streaming=True` to disable streaming for the chat model.\n\n=== \"chat model interface\"\n\n      ```python\n      from langchain_openai import ChatOpenAI\n\n      llm = ChatOpenAI(model=\"o1-preview\", disable_streaming=True) # (1)!\n      ```\n\n      1. Set `disable_streaming=True` to disable streaming for the chat model.\n\n\n\n\n\n### Async with Python < 3.11 { #async }\n\nIn Python versions < 3.11, [asyncio tasks](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task) do not support the `context` parameter.  \nThis limits LangGraph ability to automatically propagate context, and affects LangGraph's streaming mechanisms in two key ways:\n\n1. You **must** explicitly pass [`RunnableConfig`](https://python.langchain.com/docs/concepts/runnables/#runnableconfig) into async LLM calls (e.g., `ainvoke()`), as callbacks are not automatically propagated.\n2. You **cannot** use `get_stream_writer()` in async nodes or tools — you must pass a `writer` argument directly.\n\n??? example \"Extended example: async LLM call with manual config\"\n\n      ```python hl_lines=\"16 29\"\n      from typing import TypedDict\n      from langgraph.graph import START, StateGraph\n      from langchain.chat_models import init_chat_model\n\n      llm = init_chat_model(model=\"openai:gpt-4o-mini\")\n\n      class State(TypedDict):\n          topic: str\n          joke: str\n\n      async def call_model(state, config): # (1)!\n          topic = state[\"topic\"]\n          print(\"Generating joke...\")\n          joke_response = await llm.ainvoke(\n              [{\"role\": \"user\", \"content\": f\"Write a joke about {topic}\"}],\n              config, # (2)!\n          )\n          return {\"joke\": joke_response.content}\n\n      graph = (\n          StateGraph(State)\n          .add_node(call_model)\n          .add_edge(START, \"call_model\")\n          .compile()\n      )\n\n      async for chunk, metadata in graph.astream(\n          {\"topic\": \"ice cream\"},\n          stream_mode=\"messages\", # (3)!\n      ):\n          if chunk.content:\n              print(chunk.content, end=\"|\", flush=True)\n      ```\n\n      1. Accept `config` as an argument in the async node function.\n      2. Pass `config` to `llm.ainvoke()` to ensure proper context propagation.\n      3. Set `stream_mode=\"messages\"` to stream LLM tokens.\n\n??? example \"Extended example: async custom streaming with stream writer\"\n\n      ```python hl_lines=\"8 21\"\n      from typing import TypedDict\n      from langgraph.types import StreamWriter\n\n      class State(TypedDict):\n            topic: str\n            joke: str\n\n      async def generate_joke(state: State, writer: StreamWriter): # (1)!\n            writer({\"custom_key\": \"Streaming custom data while generating a joke\"})\n            return {\"joke\": f\"This is a joke about {state['topic']}\"}\n\n      graph = (\n            StateGraph(State)\n            .add_node(generate_joke)\n            .add_edge(START, \"generate_joke\")\n            .compile()\n      )\n\n      async for chunk in graph.astream(\n            {\"topic\": \"ice cream\"},\n            stream_mode=\"custom\", # (2)!\n      ):\n            print(chunk)\n      ```\n\n      1. Add `writer` as an argument in the function signature of the async node or tool. LangGraph will automatically pass the stream writer to the function.\n      2. Set `stream_mode=\"custom\"` to receive the custom data in the stream.\n\n\n", "title": "Stream outputs", "url": "how-tos/streaming/"}</script></meta></head>
<body data-md-color-accent="gray" data-md-color-primary="white" data-md-color-scheme="default" dir="ltr">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T35S4S46" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#stream-outputs">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<button aria-label="Don't show this again" class="md-banner__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
            
            
Our new LangChain Academy Course Deep Research with LangGraph is now live! <a href="https://academy.langchain.com/courses/deep-research-with-langgraph/?utm_medium=internal&amp;utm_source=docs&amp;utm_campaign=q3-2025_deep-research-course_co" target="_blank">Enroll for free</a>.

          </div>
<script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
</aside>
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="LangGraph" class="md-header__button md-logo" data-md-component="logo" href="../.." title="LangGraph">
<img alt="logo" class="logo-light" src="../../static/wordmark_dark.svg"/>
<img alt="logo" class="logo-dark" src="../../static/wordmark_light.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            LangGraph
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Stream outputs
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="gray" data-md-color-media="" data-md-color-primary="white" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="white" data-md-color-media="" data-md-color-primary="grey" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<a aria-label="Share" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="Share">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/langchain-ai/langgraph" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
          
  
  
    
  
  Get started

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../guides/">
          
  
  
    
  
  Guides

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../reference/">
          
  
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../examples/">
          
  
  
    
  
  Examples

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../additional-resources/">
          
  
  
    
  
  Additional resources

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="LangGraph" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="LangGraph">
<img alt="logo" class="logo-light" src="../../static/wordmark_dark.svg"/>
<img alt="logo" class="logo-dark" src="../../static/wordmark_light.svg"/>
</a>
    LangGraph
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/langchain-ai/langgraph" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Get started
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../guides/">
<span class="md-ellipsis">
    Guides
    
  </span>
</a>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Guides
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
<span class="md-ellipsis">
    Agent development
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_2">
<span class="md-nav__icon md-icon"></span>
            Agent development
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../agents/overview/">
<span class="md-ellipsis">
    Overview
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../agents/run_agents/">
<span class="md-ellipsis">
    Run an agent
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
<span class="md-ellipsis">
    LangGraph APIs
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_3">
<span class="md-nav__icon md-icon"></span>
            LangGraph APIs
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/low_level/">
<span class="md-ellipsis">
    Graph API
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/functional_api/">
<span class="md-ellipsis">
    Functional API
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../concepts/pregel/">
<span class="md-ellipsis">
    Runtime
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="">
<span class="md-ellipsis">
    Core capabilities
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_2_4_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_4">
<span class="md-nav__icon md-icon"></span>
            Core capabilities
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2_4_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_4_1" id="__nav_2_4_1_label" tabindex="0">
<span class="md-ellipsis">
    Streaming
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_2_4_1_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_2_4_1">
<span class="md-nav__icon md-icon"></span>
            Streaming
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../concepts/streaming/">
<span class="md-ellipsis">
    Overview
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Stream outputs
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Stream outputs
    
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#supported-stream-modes">
<span class="md-ellipsis">
      Supported stream modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-from-an-agent">
<span class="md-ellipsis">
      Stream from an agent
    </span>
</a>
<nav aria-label="Stream from an agent" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#agent-progress">
<span class="md-ellipsis">
      Agent progress
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#llm-tokens">
<span class="md-ellipsis">
      LLM tokens
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#tool-updates">
<span class="md-ellipsis">
      Tool updates
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-multiple-modes">
<span class="md-ellipsis">
      Stream multiple modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#disable-streaming">
<span class="md-ellipsis">
      Disable streaming
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-from-a-workflow">
<span class="md-ellipsis">
      Stream from a workflow
    </span>
</a>
<nav aria-label="Stream from a workflow" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-usage-example">
<span class="md-ellipsis">
      Basic usage example
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-multiple-modes_1">
<span class="md-ellipsis">
      Stream multiple modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-graph-state">
<span class="md-ellipsis">
      Stream graph state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-subgraph-outputs">
<span class="md-ellipsis">
      Stream subgraph outputs
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#debug">
<span class="md-ellipsis">
      Debugging
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#messages">
<span class="md-ellipsis">
      LLM tokens
    </span>
</a>
<nav aria-label="LLM tokens" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-by-llm-invocation">
<span class="md-ellipsis">
      Filter by LLM invocation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-by-node">
<span class="md-ellipsis">
      Filter by node
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-custom-data">
<span class="md-ellipsis">
      Stream custom data
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#use-with-any-llm">
<span class="md-ellipsis">
      Use with any LLM
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#disable-streaming-for-specific-chat-models">
<span class="md-ellipsis">
      Disable streaming for specific chat models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#async">
<span class="md-ellipsis">
      Async with Python &lt; 3.11
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/persistence/">
<span class="md-ellipsis">
    Persistence
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/durable_execution/">
<span class="md-ellipsis">
    Durable execution
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/memory/">
<span class="md-ellipsis">
    Memory
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../agents/context/">
<span class="md-ellipsis">
    Context
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../agents/models/">
<span class="md-ellipsis">
    Models
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/tools/">
<span class="md-ellipsis">
    Tools
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/human_in_the_loop/">
<span class="md-ellipsis">
    Human-in-the-loop
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/time-travel/">
<span class="md-ellipsis">
    Time travel
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/subgraphs/">
<span class="md-ellipsis">
    Subgraphs
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/multi_agent/">
<span class="md-ellipsis">
    Multi-agent
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/mcp/">
<span class="md-ellipsis">
    MCP
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../concepts/tracing/">
<span class="md-ellipsis">
    Tracing
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../reference/">
<span class="md-ellipsis">
    Reference
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../examples/">
<span class="md-ellipsis">
    Examples
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../additional-resources/">
<span class="md-ellipsis">
    Additional resources
    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#supported-stream-modes">
<span class="md-ellipsis">
      Supported stream modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-from-an-agent">
<span class="md-ellipsis">
      Stream from an agent
    </span>
</a>
<nav aria-label="Stream from an agent" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#agent-progress">
<span class="md-ellipsis">
      Agent progress
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#llm-tokens">
<span class="md-ellipsis">
      LLM tokens
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#tool-updates">
<span class="md-ellipsis">
      Tool updates
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-multiple-modes">
<span class="md-ellipsis">
      Stream multiple modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#disable-streaming">
<span class="md-ellipsis">
      Disable streaming
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-from-a-workflow">
<span class="md-ellipsis">
      Stream from a workflow
    </span>
</a>
<nav aria-label="Stream from a workflow" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#basic-usage-example">
<span class="md-ellipsis">
      Basic usage example
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-multiple-modes_1">
<span class="md-ellipsis">
      Stream multiple modes
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-graph-state">
<span class="md-ellipsis">
      Stream graph state
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-subgraph-outputs">
<span class="md-ellipsis">
      Stream subgraph outputs
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#debug">
<span class="md-ellipsis">
      Debugging
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#messages">
<span class="md-ellipsis">
      LLM tokens
    </span>
</a>
<nav aria-label="LLM tokens" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-by-llm-invocation">
<span class="md-ellipsis">
      Filter by LLM invocation
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#filter-by-node">
<span class="md-ellipsis">
      Filter by node
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#stream-custom-data">
<span class="md-ellipsis">
      Stream custom data
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#use-with-any-llm">
<span class="md-ellipsis">
      Use with any LLM
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#disable-streaming-for-specific-chat-models">
<span class="md-ellipsis">
      Disable streaming for specific chat models
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#async">
<span class="md-ellipsis">
      Async with Python &lt; 3.11
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<div class="notebook-links">
</div>
<a class="md-content__button md-icon" href="https://github.com/langchain-ai/langgraph/edit/main/docs/docs/how-tos/streaming.md" rel="edit" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<h1 id="stream-outputs">Stream outputs<a class="headerlink" href="#stream-outputs" title="Permanent link">¶</a></h1>
<p>You can <a href="../../concepts/streaming/">stream outputs</a> from a LangGraph agent or workflow.</p>
<h2 id="supported-stream-modes">Supported stream modes<a class="headerlink" href="#supported-stream-modes" title="Permanent link">¶</a></h2>
<p>Pass one or more of the following stream modes as a list to the <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.stream"><code>stream()</code></a> or <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.astream"><code>astream()</code></a> methods:</p>
<table>
<thead>
<tr>
<th>Mode</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>values</code></td>
<td>Streams the full value of the state after each step of the graph.</td>
</tr>
<tr>
<td><code>updates</code></td>
<td>Streams the updates to the state after each step of the graph. If multiple updates are made in the same step (e.g., multiple nodes are run), those updates are streamed separately.</td>
</tr>
<tr>
<td><code>custom</code></td>
<td>Streams custom data from inside your graph nodes.</td>
</tr>
<tr>
<td><code>messages</code></td>
<td>Streams 2-tuples (LLM token, metadata) from any graph nodes where an LLM is invoked.</td>
</tr>
<tr>
<td><code>debug</code></td>
<td>Streams as much information as possible throughout the execution of the graph.</td>
</tr>
</tbody>
</table>
<h2 id="stream-from-an-agent">Stream from an agent<a class="headerlink" href="#stream-from-an-agent" title="Permanent link">¶</a></h2>
<h3 id="agent-progress">Agent progress<a class="headerlink" href="#agent-progress" title="Permanent link">¶</a></h3>
<p>To stream agent progress, use the <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.stream"><code>stream()</code></a> or <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.astream"><code>astream()</code></a> methods with <code>stream_mode="updates"</code>. This emits an event after every agent step.</p>
<p>For example, if you have an agent that calls a tool once, you should see the following updates:</p>
<ul>
<li><strong>LLM node</strong>: AI message with tool call requests</li>
<li><strong>Tool node</strong>: Tool message with execution result</li>
<li><strong>LLM node</strong>: Final AI response</li>
</ul>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"><input id="__tabbed_1_2" name="__tabbed_1" type="radio"><div class="tabbed-labels"><label for="__tabbed_1_1">Sync</label><label for="__tabbed_1_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="p">)</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="hll"><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span></span><span id="__span-0-6"><a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-0-7"><a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span>
</span></span><span id="__span-0-8"><a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="p">):</span>
</span><span id="__span-0-9"><a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-0-10"><a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-1-4"><a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="p">)</span>
</span><span id="__span-1-5"><a href="#__codelineno-1-5" id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="hll"><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span></span><span id="__span-1-6"><a href="#__codelineno-1-6" id="__codelineno-1-6" name="__codelineno-1-6"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-1-7"><a href="#__codelineno-1-7" id="__codelineno-1-7" name="__codelineno-1-7"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span>
</span></span><span id="__span-1-8"><a href="#__codelineno-1-8" id="__codelineno-1-8" name="__codelineno-1-8"></a><span class="p">):</span>
</span><span id="__span-1-9"><a href="#__codelineno-1-9" id="__codelineno-1-9" name="__codelineno-1-9"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-1-10"><a href="#__codelineno-1-10" id="__codelineno-1-10" name="__codelineno-1-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></input></div>
<h3 id="llm-tokens">LLM tokens<a class="headerlink" href="#llm-tokens" title="Permanent link">¶</a></h3>
<p>To stream tokens as they are produced by the LLM, use <code>stream_mode="messages"</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio"><input id="__tabbed_2_2" name="__tabbed_2" type="radio"><div class="tabbed-labels"><label for="__tabbed_2_1">Sync</label><label for="__tabbed_2_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-2-3"><a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-2-4"><a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="p">)</span>
</span><span id="__span-2-5"><a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="hll"><span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span></span><span id="__span-2-6"><a href="#__codelineno-2-6" id="__codelineno-2-6" name="__codelineno-2-6"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-2-7"><a href="#__codelineno-2-7" id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span>
</span></span><span id="__span-2-8"><a href="#__codelineno-2-8" id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="p">):</span>
</span><span id="__span-2-9"><a href="#__codelineno-2-9" id="__codelineno-2-9" name="__codelineno-2-9"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="n">token</span><span class="p">)</span>
</span><span id="__span-2-10"><a href="#__codelineno-2-10" id="__codelineno-2-10" name="__codelineno-2-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Metadata"</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</span><span id="__span-2-11"><a href="#__codelineno-2-11" id="__codelineno-2-11" name="__codelineno-2-11"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-3-3"><a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-3-4"><a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="p">)</span>
</span><span id="__span-3-5"><a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="hll"><span class="k">async</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span></span><span id="__span-3-6"><a href="#__codelineno-3-6" id="__codelineno-3-6" name="__codelineno-3-6"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-3-7"><a href="#__codelineno-3-7" id="__codelineno-3-7" name="__codelineno-3-7"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span>
</span></span><span id="__span-3-8"><a href="#__codelineno-3-8" id="__codelineno-3-8" name="__codelineno-3-8"></a><span class="p">):</span>
</span><span id="__span-3-9"><a href="#__codelineno-3-9" id="__codelineno-3-9" name="__codelineno-3-9"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Token"</span><span class="p">,</span> <span class="n">token</span><span class="p">)</span>
</span><span id="__span-3-10"><a href="#__codelineno-3-10" id="__codelineno-3-10" name="__codelineno-3-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Metadata"</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)</span>
</span><span id="__span-3-11"><a href="#__codelineno-3-11" id="__codelineno-3-11" name="__codelineno-3-11"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></input></div>
<h3 id="tool-updates">Tool updates<a class="headerlink" href="#tool-updates" title="Permanent link">¶</a></h3>
<p>To stream updates from tools as they are executed, you can use <a href="https://langchain-ai.github.io/langgraph/reference/config/#langgraph.config.get_stream_writer">get_stream_writer</a>.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio"><input id="__tabbed_3_2" name="__tabbed_3" type="radio"><div class="tabbed-labels"><label for="__tabbed_3_1">Sync</label><label for="__tabbed_3_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_stream_writer</span>
</span></span><span id="__span-4-2"><a href="#__codelineno-4-2" id="__codelineno-4-2" name="__codelineno-4-2"></a>
</span><span id="__span-4-3"><a href="#__codelineno-4-3" id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_weather</span><span class="p">(</span><span class="n">city</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="__span-4-4"><a href="#__codelineno-4-4" id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="w">    </span><span class="sd">"""Get weather for a given city."""</span>
</span><span id="__span-4-5"><a href="#__codelineno-4-5" id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="hll">    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span>
</span></span><span id="__span-4-6"><a href="#__codelineno-4-6" id="__codelineno-4-6" name="__codelineno-4-6"></a>    <span class="c1"># stream any arbitrary data</span>
</span><span id="__span-4-7"><a href="#__codelineno-4-7" id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="hll">    <span class="n">writer</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Looking up data for city: </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></span><span id="__span-4-8"><a href="#__codelineno-4-8" id="__codelineno-4-8" name="__codelineno-4-8"></a>    <span class="k">return</span> <span class="sa">f</span><span class="s2">"It's always sunny in </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2">!"</span>
</span><span id="__span-4-9"><a href="#__codelineno-4-9" id="__codelineno-4-9" name="__codelineno-4-9"></a>
</span><span id="__span-4-10"><a href="#__codelineno-4-10" id="__codelineno-4-10" name="__codelineno-4-10"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-4-11"><a href="#__codelineno-4-11" id="__codelineno-4-11" name="__codelineno-4-11"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-4-12"><a href="#__codelineno-4-12" id="__codelineno-4-12" name="__codelineno-4-12"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-4-13"><a href="#__codelineno-4-13" id="__codelineno-4-13" name="__codelineno-4-13"></a><span class="p">)</span>
</span><span id="__span-4-14"><a href="#__codelineno-4-14" id="__codelineno-4-14" name="__codelineno-4-14"></a>
</span><span id="__span-4-15"><a href="#__codelineno-4-15" id="__codelineno-4-15" name="__codelineno-4-15"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-4-16"><a href="#__codelineno-4-16" id="__codelineno-4-16" name="__codelineno-4-16"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-4-17"><a href="#__codelineno-4-17" id="__codelineno-4-17" name="__codelineno-4-17"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span>
</span></span><span id="__span-4-18"><a href="#__codelineno-4-18" id="__codelineno-4-18" name="__codelineno-4-18"></a><span class="p">):</span>
</span><span id="__span-4-19"><a href="#__codelineno-4-19" id="__codelineno-4-19" name="__codelineno-4-19"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-4-20"><a href="#__codelineno-4-20" id="__codelineno-4-20" name="__codelineno-4-20"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="hll"><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_stream_writer</span>
</span></span><span id="__span-5-2"><a href="#__codelineno-5-2" id="__codelineno-5-2" name="__codelineno-5-2"></a>
</span><span id="__span-5-3"><a href="#__codelineno-5-3" id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_weather</span><span class="p">(</span><span class="n">city</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="__span-5-4"><a href="#__codelineno-5-4" id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="w">    </span><span class="sd">"""Get weather for a given city."""</span>
</span><span id="__span-5-5"><a href="#__codelineno-5-5" id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="hll">    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span>
</span></span><span id="__span-5-6"><a href="#__codelineno-5-6" id="__codelineno-5-6" name="__codelineno-5-6"></a>    <span class="c1"># stream any arbitrary data</span>
</span><span id="__span-5-7"><a href="#__codelineno-5-7" id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="hll">    <span class="n">writer</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Looking up data for city: </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span></span><span id="__span-5-8"><a href="#__codelineno-5-8" id="__codelineno-5-8" name="__codelineno-5-8"></a>    <span class="k">return</span> <span class="sa">f</span><span class="s2">"It's always sunny in </span><span class="si">{</span><span class="n">city</span><span class="si">}</span><span class="s2">!"</span>
</span><span id="__span-5-9"><a href="#__codelineno-5-9" id="__codelineno-5-9" name="__codelineno-5-9"></a>
</span><span id="__span-5-10"><a href="#__codelineno-5-10" id="__codelineno-5-10" name="__codelineno-5-10"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-5-11"><a href="#__codelineno-5-11" id="__codelineno-5-11" name="__codelineno-5-11"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-5-12"><a href="#__codelineno-5-12" id="__codelineno-5-12" name="__codelineno-5-12"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-5-13"><a href="#__codelineno-5-13" id="__codelineno-5-13" name="__codelineno-5-13"></a><span class="p">)</span>
</span><span id="__span-5-14"><a href="#__codelineno-5-14" id="__codelineno-5-14" name="__codelineno-5-14"></a>
</span><span id="__span-5-15"><a href="#__codelineno-5-15" id="__codelineno-5-15" name="__codelineno-5-15"></a><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-5-16"><a href="#__codelineno-5-16" id="__codelineno-5-16" name="__codelineno-5-16"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-5-17"><a href="#__codelineno-5-17" id="__codelineno-5-17" name="__codelineno-5-17"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span>
</span></span><span id="__span-5-18"><a href="#__codelineno-5-18" id="__codelineno-5-18" name="__codelineno-5-18"></a><span class="p">):</span>
</span><span id="__span-5-19"><a href="#__codelineno-5-19" id="__codelineno-5-19" name="__codelineno-5-19"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-5-20"><a href="#__codelineno-5-20" id="__codelineno-5-20" name="__codelineno-5-20"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></input></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you add <code>get_stream_writer</code> inside your tool, you won't be able to invoke the tool outside of a LangGraph execution context.</p>
</div>
<h3 id="stream-multiple-modes">Stream multiple modes<a class="headerlink" href="#stream-multiple-modes" title="Permanent link">¶</a></h3>
<p>You can specify multiple streaming modes by passing stream mode as a list: <code>stream_mode=["updates", "messages", "custom"]</code>:</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio"><input id="__tabbed_4_2" name="__tabbed_4" type="radio"><div class="tabbed-labels"><label for="__tabbed_4_1">Sync</label><label for="__tabbed_4_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-6-2"><a href="#__codelineno-6-2" id="__codelineno-6-2" name="__codelineno-6-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-6-3"><a href="#__codelineno-6-3" id="__codelineno-6-3" name="__codelineno-6-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-6-4"><a href="#__codelineno-6-4" id="__codelineno-6-4" name="__codelineno-6-4"></a><span class="p">)</span>
</span><span id="__span-6-5"><a href="#__codelineno-6-5" id="__codelineno-6-5" name="__codelineno-6-5"></a>
</span><span id="__span-6-6"><a href="#__codelineno-6-6" id="__codelineno-6-6" name="__codelineno-6-6"></a><span class="k">for</span> <span class="n">stream_mode</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-6-7"><a href="#__codelineno-6-7" id="__codelineno-6-7" name="__codelineno-6-7"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-6-8"><a href="#__codelineno-6-8" id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="p">[</span><span class="s2">"updates"</span><span class="p">,</span> <span class="s2">"messages"</span><span class="p">,</span> <span class="s2">"custom"</span><span class="p">]</span>
</span></span><span id="__span-6-9"><a href="#__codelineno-6-9" id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="p">):</span>
</span><span id="__span-6-10"><a href="#__codelineno-6-10" id="__codelineno-6-10" name="__codelineno-6-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-6-11"><a href="#__codelineno-6-11" id="__codelineno-6-11" name="__codelineno-6-11"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span>
</span><span id="__span-7-2"><a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a>    <span class="n">model</span><span class="o">=</span><span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-7-3"><a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a>    <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="n">get_weather</span><span class="p">],</span>
</span><span id="__span-7-4"><a href="#__codelineno-7-4" id="__codelineno-7-4" name="__codelineno-7-4"></a><span class="p">)</span>
</span><span id="__span-7-5"><a href="#__codelineno-7-5" id="__codelineno-7-5" name="__codelineno-7-5"></a>
</span><span id="__span-7-6"><a href="#__codelineno-7-6" id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="k">async</span> <span class="k">for</span> <span class="n">stream_mode</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">agent</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-7-7"><a href="#__codelineno-7-7" id="__codelineno-7-7" name="__codelineno-7-7"></a>    <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="s2">"what is the weather in sf"</span><span class="p">}]},</span>
</span><span id="__span-7-8"><a href="#__codelineno-7-8" id="__codelineno-7-8" name="__codelineno-7-8"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="p">[</span><span class="s2">"updates"</span><span class="p">,</span> <span class="s2">"messages"</span><span class="p">,</span> <span class="s2">"custom"</span><span class="p">]</span>
</span></span><span id="__span-7-9"><a href="#__codelineno-7-9" id="__codelineno-7-9" name="__codelineno-7-9"></a><span class="p">):</span>
</span><span id="__span-7-10"><a href="#__codelineno-7-10" id="__codelineno-7-10" name="__codelineno-7-10"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span><span id="__span-7-11"><a href="#__codelineno-7-11" id="__codelineno-7-11" name="__codelineno-7-11"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></input></div>
<h3 id="disable-streaming">Disable streaming<a class="headerlink" href="#disable-streaming" title="Permanent link">¶</a></h3>
<p>In some applications you might need to disable streaming of individual tokens for a given model. This is useful in <a href="../../agents/multi-agent/">multi-agent</a> systems to control which agents stream their output.</p>
<p>See the <a href="../../agents/models/#disable-streaming">Models</a> guide to learn how to disable streaming.</p>
<h2 id="stream-from-a-workflow">Stream from a workflow<a class="headerlink" href="#stream-from-a-workflow" title="Permanent link">¶</a></h2>
<h3 id="basic-usage-example">Basic usage example<a class="headerlink" href="#basic-usage-example" title="Permanent link">¶</a></h3>
<p>LangGraph graphs expose the <a href="https://langchain-ai.github.io/langgraph/reference/pregel/#langgraph.pregel.Pregel.stream"><code>.stream()</code></a> (sync) and <a href="https://langchain-ai.github.io/langgraph/reference/pregel/#langgraph.pregel.Pregel.astream"><code>.astream()</code></a> (async) methods to yield streamed outputs as iterators.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio"><input id="__tabbed_5_2" name="__tabbed_5" type="radio"><div class="tabbed-labels"><label for="__tabbed_5_1">Sync</label><label for="__tabbed_5_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">):</span>
</span><span id="__span-8-2"><a href="#__codelineno-8-2" id="__codelineno-8-2" name="__codelineno-8-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a href="#__codelineno-9-1" id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">):</span>
</span><span id="__span-9-2"><a href="#__codelineno-9-2" id="__codelineno-9-2" name="__codelineno-9-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></input></div>
<details class="example">
<summary>Extended example: streaming updates</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a href="#__codelineno-10-1" id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-10-2"><a href="#__codelineno-10-2" id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>
</span><span id="__span-10-3"><a href="#__codelineno-10-3" id="__codelineno-10-3" name="__codelineno-10-3"></a>
</span><span id="__span-10-4"><a href="#__codelineno-10-4" id="__codelineno-10-4" name="__codelineno-10-4"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-10-5"><a href="#__codelineno-10-5" id="__codelineno-10-5" name="__codelineno-10-5"></a>    <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-10-6"><a href="#__codelineno-10-6" id="__codelineno-10-6" name="__codelineno-10-6"></a>    <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-10-7"><a href="#__codelineno-10-7" id="__codelineno-10-7" name="__codelineno-10-7"></a>
</span><span id="__span-10-8"><a href="#__codelineno-10-8" id="__codelineno-10-8" name="__codelineno-10-8"></a><span class="k">def</span><span class="w"> </span><span class="nf">refine_topic</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-10-9"><a href="#__codelineno-10-9" id="__codelineno-10-9" name="__codelineno-10-9"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span> <span class="o">+</span> <span class="s2">" and cats"</span><span class="p">}</span>
</span><span id="__span-10-10"><a href="#__codelineno-10-10" id="__codelineno-10-10" name="__codelineno-10-10"></a>
</span><span id="__span-10-11"><a href="#__codelineno-10-11" id="__codelineno-10-11" name="__codelineno-10-11"></a><span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-10-12"><a href="#__codelineno-10-12" id="__codelineno-10-12" name="__codelineno-10-12"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"This is a joke about </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">'topic'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">}</span>
</span><span id="__span-10-13"><a href="#__codelineno-10-13" id="__codelineno-10-13" name="__codelineno-10-13"></a>
</span><span id="__span-10-14"><a href="#__codelineno-10-14" id="__codelineno-10-14" name="__codelineno-10-14"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-10-15"><a href="#__codelineno-10-15" id="__codelineno-10-15" name="__codelineno-10-15"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-10-16"><a href="#__codelineno-10-16" id="__codelineno-10-16" name="__codelineno-10-16"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">refine_topic</span><span class="p">)</span>
</span><span id="__span-10-17"><a href="#__codelineno-10-17" id="__codelineno-10-17" name="__codelineno-10-17"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">generate_joke</span><span class="p">)</span>
</span><span id="__span-10-18"><a href="#__codelineno-10-18" id="__codelineno-10-18" name="__codelineno-10-18"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"refine_topic"</span><span class="p">)</span>
</span><span id="__span-10-19"><a href="#__codelineno-10-19" id="__codelineno-10-19" name="__codelineno-10-19"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"refine_topic"</span><span class="p">,</span> <span class="s2">"generate_joke"</span><span class="p">)</span>
</span><span id="__span-10-20"><a href="#__codelineno-10-20" id="__codelineno-10-20" name="__codelineno-10-20"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"generate_joke"</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>
</span><span id="__span-10-21"><a href="#__codelineno-10-21" id="__codelineno-10-21" name="__codelineno-10-21"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-10-22"><a href="#__codelineno-10-22" id="__codelineno-10-22" name="__codelineno-10-22"></a><span class="p">)</span>
</span><span id="__span-10-23"><a href="#__codelineno-10-23" id="__codelineno-10-23" name="__codelineno-10-23"></a>
</span><span id="__span-10-24"><a href="#__codelineno-10-24" id="__codelineno-10-24" name="__codelineno-10-24"></a><span class="hll"><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-10-25"><a href="#__codelineno-10-25" id="__codelineno-10-25" name="__codelineno-10-25"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-10-26"><a href="#__codelineno-10-26" id="__codelineno-10-26" name="__codelineno-10-26"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">,</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-10-27"><a href="#__codelineno-10-27" id="__codelineno-10-27" name="__codelineno-10-27"></a><span class="p">):</span>
</span><span id="__span-10-28"><a href="#__codelineno-10-28" id="__codelineno-10-28" name="__codelineno-10-28"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>The <code>stream()</code> method returns an iterator that yields streamed outputs.</li>
<li>Set <code>stream_mode="updates"</code> to stream only the updates to the graph state after each node. Other stream modes are also available. See <a href="#supported-stream-modes">supported stream modes</a> for details.</li>
</ol>
<p><code>output
  {'refineTopic': {'topic': 'ice cream and cats'}}
  {'generateJoke': {'joke': 'This is a joke about ice cream and cats'}}</code>                                                                                                   |</p>
</details>
<h3 id="stream-multiple-modes_1">Stream multiple modes<a class="headerlink" href="#stream-multiple-modes_1" title="Permanent link">¶</a></h3>
<p>You can pass a list as the <code>stream_mode</code> parameter to stream multiple modes at once.</p>
<p>The streamed outputs will be tuples of <code>(mode, chunk)</code> where <code>mode</code> is the name of the stream mode and <code>chunk</code> is the data streamed by that mode.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="6:2"><input checked="checked" id="__tabbed_6_1" name="__tabbed_6" type="radio"><input id="__tabbed_6_2" name="__tabbed_6" type="radio"/><div class="tabbed-labels"><label for="__tabbed_6_1">Sync</label><label for="__tabbed_6_2">Async</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a href="#__codelineno-11-1" id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="k">for</span> <span class="n">mode</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="p">[</span><span class="s2">"updates"</span><span class="p">,</span> <span class="s2">"custom"</span><span class="p">]):</span>
</span><span id="__span-11-2"><a href="#__codelineno-11-2" id="__codelineno-11-2" name="__codelineno-11-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a href="#__codelineno-12-1" id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="k">async</span> <span class="k">for</span> <span class="n">mode</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="p">[</span><span class="s2">"updates"</span><span class="p">,</span> <span class="s2">"custom"</span><span class="p">]):</span>
</span><span id="__span-12-2"><a href="#__codelineno-12-2" id="__codelineno-12-2" name="__codelineno-12-2"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</input></div>
<h3 id="stream-graph-state">Stream graph state<a class="headerlink" href="#stream-graph-state" title="Permanent link">¶</a></h3>
<p>Use the stream modes <code>updates</code> and <code>values</code> to stream the state of the graph as it executes.</p>
<ul>
<li><code>updates</code> streams the <strong>updates</strong> to the state after each step of the graph.</li>
<li><code>values</code> streams the <strong>full value</strong> of the state after each step of the graph.</li>
</ul>
<p><sup><i>API Reference: <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph">StateGraph</a> | <a href="https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START">START</a> | <a href="https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.END">END</a></i></sup></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a href="#__codelineno-13-1" id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-13-2"><a href="#__codelineno-13-2" id="__codelineno-13-2" name="__codelineno-13-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span><span class="p">,</span> <span class="n">END</span>
</span><span id="__span-13-3"><a href="#__codelineno-13-3" id="__codelineno-13-3" name="__codelineno-13-3"></a>
</span><span id="__span-13-4"><a href="#__codelineno-13-4" id="__codelineno-13-4" name="__codelineno-13-4"></a>
</span><span id="__span-13-5"><a href="#__codelineno-13-5" id="__codelineno-13-5" name="__codelineno-13-5"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-13-6"><a href="#__codelineno-13-6" id="__codelineno-13-6" name="__codelineno-13-6"></a>  <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-13-7"><a href="#__codelineno-13-7" id="__codelineno-13-7" name="__codelineno-13-7"></a>  <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-13-8"><a href="#__codelineno-13-8" id="__codelineno-13-8" name="__codelineno-13-8"></a>
</span><span id="__span-13-9"><a href="#__codelineno-13-9" id="__codelineno-13-9" name="__codelineno-13-9"></a>
</span><span id="__span-13-10"><a href="#__codelineno-13-10" id="__codelineno-13-10" name="__codelineno-13-10"></a><span class="k">def</span><span class="w"> </span><span class="nf">refine_topic</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-13-11"><a href="#__codelineno-13-11" id="__codelineno-13-11" name="__codelineno-13-11"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span> <span class="o">+</span> <span class="s2">" and cats"</span><span class="p">}</span>
</span><span id="__span-13-12"><a href="#__codelineno-13-12" id="__codelineno-13-12" name="__codelineno-13-12"></a>
</span><span id="__span-13-13"><a href="#__codelineno-13-13" id="__codelineno-13-13" name="__codelineno-13-13"></a>
</span><span id="__span-13-14"><a href="#__codelineno-13-14" id="__codelineno-13-14" name="__codelineno-13-14"></a><span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-13-15"><a href="#__codelineno-13-15" id="__codelineno-13-15" name="__codelineno-13-15"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"This is a joke about </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">'topic'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">}</span>
</span><span id="__span-13-16"><a href="#__codelineno-13-16" id="__codelineno-13-16" name="__codelineno-13-16"></a>
</span><span id="__span-13-17"><a href="#__codelineno-13-17" id="__codelineno-13-17" name="__codelineno-13-17"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-13-18"><a href="#__codelineno-13-18" id="__codelineno-13-18" name="__codelineno-13-18"></a>  <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-13-19"><a href="#__codelineno-13-19" id="__codelineno-13-19" name="__codelineno-13-19"></a>  <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">refine_topic</span><span class="p">)</span>
</span><span id="__span-13-20"><a href="#__codelineno-13-20" id="__codelineno-13-20" name="__codelineno-13-20"></a>  <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">generate_joke</span><span class="p">)</span>
</span><span id="__span-13-21"><a href="#__codelineno-13-21" id="__codelineno-13-21" name="__codelineno-13-21"></a>  <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"refine_topic"</span><span class="p">)</span>
</span><span id="__span-13-22"><a href="#__codelineno-13-22" id="__codelineno-13-22" name="__codelineno-13-22"></a>  <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"refine_topic"</span><span class="p">,</span> <span class="s2">"generate_joke"</span><span class="p">)</span>
</span><span id="__span-13-23"><a href="#__codelineno-13-23" id="__codelineno-13-23" name="__codelineno-13-23"></a>  <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"generate_joke"</span><span class="p">,</span> <span class="n">END</span><span class="p">)</span>
</span><span id="__span-13-24"><a href="#__codelineno-13-24" id="__codelineno-13-24" name="__codelineno-13-24"></a>  <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-13-25"><a href="#__codelineno-13-25" id="__codelineno-13-25" name="__codelineno-13-25"></a><span class="p">)</span>
</span></code></pre></div>
<div class="tabbed-set tabbed-alternate" data-tabs="7:2"><input checked="checked" id="__tabbed_7_1" name="__tabbed_7" type="radio"/><input id="__tabbed_7_2" name="__tabbed_7" type="radio"/><div class="tabbed-labels"><label for="__tabbed_7_1">updates</label><label for="__tabbed_7_2">values</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Use this to stream only the <strong>state updates</strong> returned by the nodes after each step. The streamed outputs include the name of the node as well as the update.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a href="#__codelineno-14-1" id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-14-2"><a href="#__codelineno-14-2" id="__codelineno-14-2" name="__codelineno-14-2"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-14-3"><a href="#__codelineno-14-3" id="__codelineno-14-3" name="__codelineno-14-3"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">,</span>
</span></span><span id="__span-14-4"><a href="#__codelineno-14-4" id="__codelineno-14-4" name="__codelineno-14-4"></a><span class="p">):</span>
</span><span id="__span-14-5"><a href="#__codelineno-14-5" id="__codelineno-14-5" name="__codelineno-14-5"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
<div class="tabbed-block">
<p>Use this to stream the <strong>full state</strong> of the graph after each step.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a href="#__codelineno-15-1" id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-15-2"><a href="#__codelineno-15-2" id="__codelineno-15-2" name="__codelineno-15-2"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-15-3"><a href="#__codelineno-15-3" id="__codelineno-15-3" name="__codelineno-15-3"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"values"</span><span class="p">,</span>
</span></span><span id="__span-15-4"><a href="#__codelineno-15-4" id="__codelineno-15-4" name="__codelineno-15-4"></a><span class="p">):</span>
</span><span id="__span-15-5"><a href="#__codelineno-15-5" id="__codelineno-15-5" name="__codelineno-15-5"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
</div>
</div>
</div>
<h3 id="stream-subgraph-outputs">Stream subgraph outputs<a class="headerlink" href="#stream-subgraph-outputs" title="Permanent link">¶</a></h3>
<p>To include outputs from <a href="../../concepts/subgraphs/">subgraphs</a> in the streamed outputs, you can set <code>subgraphs=True</code> in the <code>.stream()</code> method of the parent graph. This will stream outputs from both the parent graph and any subgraphs.</p>
<p>The outputs will be streamed as tuples <code>(namespace, data)</code>, where <code>namespace</code> is a tuple with the path to the node where a subgraph is invoked, e.g. <code>("parent_node:&lt;task_id&gt;", "child_node:&lt;task_id&gt;")</code>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-16-1"><a href="#__codelineno-16-1" id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-16-2"><a href="#__codelineno-16-2" id="__codelineno-16-2" name="__codelineno-16-2"></a>    <span class="p">{</span><span class="s2">"foo"</span><span class="p">:</span> <span class="s2">"foo"</span><span class="p">},</span>
</span><span id="__span-16-3"><a href="#__codelineno-16-3" id="__codelineno-16-3" name="__codelineno-16-3"></a><span class="hll">    <span class="n">subgraphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-16-4"><a href="#__codelineno-16-4" id="__codelineno-16-4" name="__codelineno-16-4"></a>    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">,</span>
</span><span id="__span-16-5"><a href="#__codelineno-16-5" id="__codelineno-16-5" name="__codelineno-16-5"></a><span class="p">):</span>
</span><span id="__span-16-6"><a href="#__codelineno-16-6" id="__codelineno-16-6" name="__codelineno-16-6"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Set <code>subgraphs=True</code> to stream outputs from subgraphs.</li>
</ol>
<details class="example">
<summary>Extended example: streaming from subgraphs</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-17-1"><a href="#__codelineno-17-1" id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">START</span><span class="p">,</span> <span class="n">StateGraph</span>
</span><span id="__span-17-2"><a href="#__codelineno-17-2" id="__codelineno-17-2" name="__codelineno-17-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-17-3"><a href="#__codelineno-17-3" id="__codelineno-17-3" name="__codelineno-17-3"></a>
</span><span id="__span-17-4"><a href="#__codelineno-17-4" id="__codelineno-17-4" name="__codelineno-17-4"></a><span class="c1"># Define subgraph</span>
</span><span id="__span-17-5"><a href="#__codelineno-17-5" id="__codelineno-17-5" name="__codelineno-17-5"></a><span class="k">class</span><span class="w"> </span><span class="nc">SubgraphState</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-17-6"><a href="#__codelineno-17-6" id="__codelineno-17-6" name="__codelineno-17-6"></a>    <span class="n">foo</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># note that this key is shared with the parent graph state</span>
</span><span id="__span-17-7"><a href="#__codelineno-17-7" id="__codelineno-17-7" name="__codelineno-17-7"></a>    <span class="n">bar</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-17-8"><a href="#__codelineno-17-8" id="__codelineno-17-8" name="__codelineno-17-8"></a>
</span><span id="__span-17-9"><a href="#__codelineno-17-9" id="__codelineno-17-9" name="__codelineno-17-9"></a><span class="k">def</span><span class="w"> </span><span class="nf">subgraph_node_1</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">SubgraphState</span><span class="p">):</span>
</span><span id="__span-17-10"><a href="#__codelineno-17-10" id="__codelineno-17-10" name="__codelineno-17-10"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"bar"</span><span class="p">:</span> <span class="s2">"bar"</span><span class="p">}</span>
</span><span id="__span-17-11"><a href="#__codelineno-17-11" id="__codelineno-17-11" name="__codelineno-17-11"></a>
</span><span id="__span-17-12"><a href="#__codelineno-17-12" id="__codelineno-17-12" name="__codelineno-17-12"></a><span class="k">def</span><span class="w"> </span><span class="nf">subgraph_node_2</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">SubgraphState</span><span class="p">):</span>
</span><span id="__span-17-13"><a href="#__codelineno-17-13" id="__codelineno-17-13" name="__codelineno-17-13"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"foo"</span><span class="p">:</span> <span class="n">state</span><span class="p">[</span><span class="s2">"foo"</span><span class="p">]</span> <span class="o">+</span> <span class="n">state</span><span class="p">[</span><span class="s2">"bar"</span><span class="p">]}</span>
</span><span id="__span-17-14"><a href="#__codelineno-17-14" id="__codelineno-17-14" name="__codelineno-17-14"></a>
</span><span id="__span-17-15"><a href="#__codelineno-17-15" id="__codelineno-17-15" name="__codelineno-17-15"></a><span class="n">subgraph_builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">SubgraphState</span><span class="p">)</span>
</span><span id="__span-17-16"><a href="#__codelineno-17-16" id="__codelineno-17-16" name="__codelineno-17-16"></a><span class="n">subgraph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">subgraph_node_1</span><span class="p">)</span>
</span><span id="__span-17-17"><a href="#__codelineno-17-17" id="__codelineno-17-17" name="__codelineno-17-17"></a><span class="n">subgraph_builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">subgraph_node_2</span><span class="p">)</span>
</span><span id="__span-17-18"><a href="#__codelineno-17-18" id="__codelineno-17-18" name="__codelineno-17-18"></a><span class="n">subgraph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"subgraph_node_1"</span><span class="p">)</span>
</span><span id="__span-17-19"><a href="#__codelineno-17-19" id="__codelineno-17-19" name="__codelineno-17-19"></a><span class="n">subgraph_builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"subgraph_node_1"</span><span class="p">,</span> <span class="s2">"subgraph_node_2"</span><span class="p">)</span>
</span><span id="__span-17-20"><a href="#__codelineno-17-20" id="__codelineno-17-20" name="__codelineno-17-20"></a><span class="n">subgraph</span> <span class="o">=</span> <span class="n">subgraph_builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-17-21"><a href="#__codelineno-17-21" id="__codelineno-17-21" name="__codelineno-17-21"></a>
</span><span id="__span-17-22"><a href="#__codelineno-17-22" id="__codelineno-17-22" name="__codelineno-17-22"></a><span class="c1"># Define parent graph</span>
</span><span id="__span-17-23"><a href="#__codelineno-17-23" id="__codelineno-17-23" name="__codelineno-17-23"></a><span class="k">class</span><span class="w"> </span><span class="nc">ParentState</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-17-24"><a href="#__codelineno-17-24" id="__codelineno-17-24" name="__codelineno-17-24"></a>    <span class="n">foo</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-17-25"><a href="#__codelineno-17-25" id="__codelineno-17-25" name="__codelineno-17-25"></a>
</span><span id="__span-17-26"><a href="#__codelineno-17-26" id="__codelineno-17-26" name="__codelineno-17-26"></a><span class="k">def</span><span class="w"> </span><span class="nf">node_1</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">ParentState</span><span class="p">):</span>
</span><span id="__span-17-27"><a href="#__codelineno-17-27" id="__codelineno-17-27" name="__codelineno-17-27"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"foo"</span><span class="p">:</span> <span class="s2">"hi! "</span> <span class="o">+</span> <span class="n">state</span><span class="p">[</span><span class="s2">"foo"</span><span class="p">]}</span>
</span><span id="__span-17-28"><a href="#__codelineno-17-28" id="__codelineno-17-28" name="__codelineno-17-28"></a>
</span><span id="__span-17-29"><a href="#__codelineno-17-29" id="__codelineno-17-29" name="__codelineno-17-29"></a><span class="n">builder</span> <span class="o">=</span> <span class="n">StateGraph</span><span class="p">(</span><span class="n">ParentState</span><span class="p">)</span>
</span><span id="__span-17-30"><a href="#__codelineno-17-30" id="__codelineno-17-30" name="__codelineno-17-30"></a><span class="n">builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">"node_1"</span><span class="p">,</span> <span class="n">node_1</span><span class="p">)</span>
</span><span id="__span-17-31"><a href="#__codelineno-17-31" id="__codelineno-17-31" name="__codelineno-17-31"></a><span class="n">builder</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="s2">"node_2"</span><span class="p">,</span> <span class="n">subgraph</span><span class="p">)</span>
</span><span id="__span-17-32"><a href="#__codelineno-17-32" id="__codelineno-17-32" name="__codelineno-17-32"></a><span class="n">builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"node_1"</span><span class="p">)</span>
</span><span id="__span-17-33"><a href="#__codelineno-17-33" id="__codelineno-17-33" name="__codelineno-17-33"></a><span class="n">builder</span><span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="s2">"node_1"</span><span class="p">,</span> <span class="s2">"node_2"</span><span class="p">)</span>
</span><span id="__span-17-34"><a href="#__codelineno-17-34" id="__codelineno-17-34" name="__codelineno-17-34"></a><span class="n">graph</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-17-35"><a href="#__codelineno-17-35" id="__codelineno-17-35" name="__codelineno-17-35"></a>
</span><span id="__span-17-36"><a href="#__codelineno-17-36" id="__codelineno-17-36" name="__codelineno-17-36"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-17-37"><a href="#__codelineno-17-37" id="__codelineno-17-37" name="__codelineno-17-37"></a>    <span class="p">{</span><span class="s2">"foo"</span><span class="p">:</span> <span class="s2">"foo"</span><span class="p">},</span>
</span><span id="__span-17-38"><a href="#__codelineno-17-38" id="__codelineno-17-38" name="__codelineno-17-38"></a>    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"updates"</span><span class="p">,</span>
</span><span id="__span-17-39"><a href="#__codelineno-17-39" id="__codelineno-17-39" name="__codelineno-17-39"></a><span class="hll">    <span class="n">subgraphs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-17-40"><a href="#__codelineno-17-40" id="__codelineno-17-40" name="__codelineno-17-40"></a><span class="p">):</span>
</span><span id="__span-17-41"><a href="#__codelineno-17-41" id="__codelineno-17-41" name="__codelineno-17-41"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Set <code>subgraphs=True</code> to stream outputs from subgraphs.</li>
</ol>
<div class="language-text highlight"><pre><span></span><code><span id="__span-18-1"><a href="#__codelineno-18-1" id="__codelineno-18-1" name="__codelineno-18-1"></a>((), {'node_1': {'foo': 'hi! foo'}})
</span><span id="__span-18-2"><a href="#__codelineno-18-2" id="__codelineno-18-2" name="__codelineno-18-2"></a>(('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_1': {'bar': 'bar'}})
</span><span id="__span-18-3"><a href="#__codelineno-18-3" id="__codelineno-18-3" name="__codelineno-18-3"></a>(('node_2:dfddc4ba-c3c5-6887-5012-a243b5b377c2',), {'subgraph_node_2': {'foo': 'hi! foobar'}})
</span><span id="__span-18-4"><a href="#__codelineno-18-4" id="__codelineno-18-4" name="__codelineno-18-4"></a>((), {'node_2': {'foo': 'hi! foobar'}})
</span></code></pre></div>
<p><strong>Note</strong> that we are receiving not just the node updates, but we also the namespaces which tell us what graph (or subgraph) we are streaming from.</p>
</details>
<h3 id="debug">Debugging<a class="headerlink" href="#debug" title="Permanent link">¶</a></h3>
<p>Use the <code>debug</code> streaming mode to stream as much information as possible throughout the execution of the graph. The streamed outputs include the name of the node as well as the full state.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-19-1"><a href="#__codelineno-19-1" id="__codelineno-19-1" name="__codelineno-19-1"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-19-2"><a href="#__codelineno-19-2" id="__codelineno-19-2" name="__codelineno-19-2"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-19-3"><a href="#__codelineno-19-3" id="__codelineno-19-3" name="__codelineno-19-3"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"debug"</span><span class="p">,</span>
</span></span><span id="__span-19-4"><a href="#__codelineno-19-4" id="__codelineno-19-4" name="__codelineno-19-4"></a><span class="p">):</span>
</span><span id="__span-19-5"><a href="#__codelineno-19-5" id="__codelineno-19-5" name="__codelineno-19-5"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="messages">LLM tokens<a class="headerlink" href="#messages" title="Permanent link">¶</a></h3>
<p>Use the <code>messages</code> streaming mode to stream Large Language Model (LLM) outputs <strong>token by token</strong> from any part of your graph, including nodes, tools, subgraphs, or tasks.</p>
<p>The streamed output from <a href="#supported-stream-modes"><code>messages</code> mode</a> is a tuple <code>(message_chunk, metadata)</code> where:</p>
<ul>
<li><code>message_chunk</code>: the token or message segment from the LLM.</li>
<li><code>metadata</code>: a dictionary containing details about the graph node and LLM invocation.</li>
</ul>
<blockquote>
<p>If your LLM is not available as a LangChain integration, you can stream its outputs using <code>custom</code> mode instead. See <a href="#use-with-any-llm">use with any LLM</a> for details.</p>
</blockquote>
<div class="admonition warning">
<p class="admonition-title">Manual config required for async in Python &lt; 3.11</p>
<p>When using Python &lt; 3.11 with async code, you must explicitly pass <code>RunnableConfig</code> to <code>ainvoke()</code> to enable proper streaming. See <a href="#async">Async with Python &lt; 3.11</a> for details or upgrade to Python 3.11+.</p>
</div>
<p><sup><i>API Reference: <a href="https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html">init_chat_model</a> | <a href="https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph">StateGraph</a> | <a href="https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START">START</a></i></sup></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-20-1"><a href="#__codelineno-20-1" id="__codelineno-20-1" name="__codelineno-20-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
</span><span id="__span-20-2"><a href="#__codelineno-20-2" id="__codelineno-20-2" name="__codelineno-20-2"></a>
</span><span id="__span-20-3"><a href="#__codelineno-20-3" id="__codelineno-20-3" name="__codelineno-20-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
</span><span id="__span-20-4"><a href="#__codelineno-20-4" id="__codelineno-20-4" name="__codelineno-20-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span>
</span><span id="__span-20-5"><a href="#__codelineno-20-5" id="__codelineno-20-5" name="__codelineno-20-5"></a>
</span><span id="__span-20-6"><a href="#__codelineno-20-6" id="__codelineno-20-6" name="__codelineno-20-6"></a>
</span><span id="__span-20-7"><a href="#__codelineno-20-7" id="__codelineno-20-7" name="__codelineno-20-7"></a><span class="nd">@dataclass</span>
</span><span id="__span-20-8"><a href="#__codelineno-20-8" id="__codelineno-20-8" name="__codelineno-20-8"></a><span class="k">class</span><span class="w"> </span><span class="nc">MyState</span><span class="p">:</span>
</span><span id="__span-20-9"><a href="#__codelineno-20-9" id="__codelineno-20-9" name="__codelineno-20-9"></a>    <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-20-10"><a href="#__codelineno-20-10" id="__codelineno-20-10" name="__codelineno-20-10"></a>    <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">""</span>
</span><span id="__span-20-11"><a href="#__codelineno-20-11" id="__codelineno-20-11" name="__codelineno-20-11"></a>
</span><span id="__span-20-12"><a href="#__codelineno-20-12" id="__codelineno-20-12" name="__codelineno-20-12"></a>
</span><span id="__span-20-13"><a href="#__codelineno-20-13" id="__codelineno-20-13" name="__codelineno-20-13"></a><span class="n">llm</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">)</span>
</span><span id="__span-20-14"><a href="#__codelineno-20-14" id="__codelineno-20-14" name="__codelineno-20-14"></a>
</span><span id="__span-20-15"><a href="#__codelineno-20-15" id="__codelineno-20-15" name="__codelineno-20-15"></a><span class="k">def</span><span class="w"> </span><span class="nf">call_model</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">MyState</span><span class="p">):</span>
</span><span id="__span-20-16"><a href="#__codelineno-20-16" id="__codelineno-20-16" name="__codelineno-20-16"></a><span class="w">    </span><span class="sd">"""Call the LLM to generate a joke about a topic"""</span>
</span><span id="__span-20-17"><a href="#__codelineno-20-17" id="__codelineno-20-17" name="__codelineno-20-17"></a><span class="hll">    <span class="n">llm_response</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-20-18"><a href="#__codelineno-20-18" id="__codelineno-20-18" name="__codelineno-20-18"></a>        <span class="p">[</span>
</span><span id="__span-20-19"><a href="#__codelineno-20-19" id="__codelineno-20-19" name="__codelineno-20-19"></a>            <span class="p">{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Generate a joke about </span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}</span>
</span><span id="__span-20-20"><a href="#__codelineno-20-20" id="__codelineno-20-20" name="__codelineno-20-20"></a>        <span class="p">]</span>
</span><span id="__span-20-21"><a href="#__codelineno-20-21" id="__codelineno-20-21" name="__codelineno-20-21"></a>    <span class="p">)</span>
</span><span id="__span-20-22"><a href="#__codelineno-20-22" id="__codelineno-20-22" name="__codelineno-20-22"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="n">llm_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-20-23"><a href="#__codelineno-20-23" id="__codelineno-20-23" name="__codelineno-20-23"></a>
</span><span id="__span-20-24"><a href="#__codelineno-20-24" id="__codelineno-20-24" name="__codelineno-20-24"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-20-25"><a href="#__codelineno-20-25" id="__codelineno-20-25" name="__codelineno-20-25"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">MyState</span><span class="p">)</span>
</span><span id="__span-20-26"><a href="#__codelineno-20-26" id="__codelineno-20-26" name="__codelineno-20-26"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">call_model</span><span class="p">)</span>
</span><span id="__span-20-27"><a href="#__codelineno-20-27" id="__codelineno-20-27" name="__codelineno-20-27"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"call_model"</span><span class="p">)</span>
</span><span id="__span-20-28"><a href="#__codelineno-20-28" id="__codelineno-20-28" name="__codelineno-20-28"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-20-29"><a href="#__codelineno-20-29" id="__codelineno-20-29" name="__codelineno-20-29"></a><span class="p">)</span>
</span><span id="__span-20-30"><a href="#__codelineno-20-30" id="__codelineno-20-30" name="__codelineno-20-30"></a>
</span><span id="__span-20-31"><a href="#__codelineno-20-31" id="__codelineno-20-31" name="__codelineno-20-31"></a><span class="k">for</span> <span class="n">message_chunk</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span> <span class="c1"># (2)!</span>
</span><span id="__span-20-32"><a href="#__codelineno-20-32" id="__codelineno-20-32" name="__codelineno-20-32"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-20-33"><a href="#__codelineno-20-33" id="__codelineno-20-33" name="__codelineno-20-33"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span>
</span></span><span id="__span-20-34"><a href="#__codelineno-20-34" id="__codelineno-20-34" name="__codelineno-20-34"></a><span class="p">):</span>
</span><span id="__span-20-35"><a href="#__codelineno-20-35" id="__codelineno-20-35" name="__codelineno-20-35"></a>    <span class="k">if</span> <span class="n">message_chunk</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
</span><span id="__span-20-36"><a href="#__codelineno-20-36" id="__codelineno-20-36" name="__codelineno-20-36"></a>        <span class="nb">print</span><span class="p">(</span><span class="n">message_chunk</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Note that the message events are emitted even when the LLM is run using <code>.invoke</code> rather than <code>.stream</code>.</li>
<li>The "messages" stream mode returns an iterator of tuples <code>(message_chunk, metadata)</code> where <code>message_chunk</code> is the token streamed by the LLM and <code>metadata</code> is a dictionary with information about the graph node where the LLM was called and other information.</li>
</ol>
<h4 id="filter-by-llm-invocation">Filter by LLM invocation<a class="headerlink" href="#filter-by-llm-invocation" title="Permanent link">¶</a></h4>
<p>You can associate <code>tags</code> with LLM invocations to filter the streamed tokens by LLM invocation.</p>
<p><sup><i>API Reference: <a href="https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html">init_chat_model</a></i></sup></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-21-1"><a href="#__codelineno-21-1" id="__codelineno-21-1" name="__codelineno-21-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
</span><span id="__span-21-2"><a href="#__codelineno-21-2" id="__codelineno-21-2" name="__codelineno-21-2"></a>
</span><span id="__span-21-3"><a href="#__codelineno-21-3" id="__codelineno-21-3" name="__codelineno-21-3"></a><span class="n">llm_1</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">'joke'</span><span class="p">])</span> <span class="c1"># (1)!</span>
</span><span id="__span-21-4"><a href="#__codelineno-21-4" id="__codelineno-21-4" name="__codelineno-21-4"></a><span class="n">llm_2</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">'poem'</span><span class="p">])</span> <span class="c1"># (2)!</span>
</span><span id="__span-21-5"><a href="#__codelineno-21-5" id="__codelineno-21-5" name="__codelineno-21-5"></a>
</span><span id="__span-21-6"><a href="#__codelineno-21-6" id="__codelineno-21-6" name="__codelineno-21-6"></a><span class="n">graph</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># define a graph that uses these LLMs</span>
</span><span id="__span-21-7"><a href="#__codelineno-21-7" id="__codelineno-21-7" name="__codelineno-21-7"></a>
</span><span id="__span-21-8"><a href="#__codelineno-21-8" id="__codelineno-21-8" name="__codelineno-21-8"></a><span class="k">async</span> <span class="k">for</span> <span class="n">msg</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>  <span class="c1"># (3)!</span>
</span><span id="__span-21-9"><a href="#__codelineno-21-9" id="__codelineno-21-9" name="__codelineno-21-9"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"cats"</span><span class="p">},</span>
</span><span id="__span-21-10"><a href="#__codelineno-21-10" id="__codelineno-21-10" name="__codelineno-21-10"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span>
</span></span><span id="__span-21-11"><a href="#__codelineno-21-11" id="__codelineno-21-11" name="__codelineno-21-11"></a><span class="p">):</span>
</span><span id="__span-21-12"><a href="#__codelineno-21-12" id="__codelineno-21-12" name="__codelineno-21-12"></a>    <span class="k">if</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"tags"</span><span class="p">]</span> <span class="o">==</span> <span class="p">[</span><span class="s2">"joke"</span><span class="p">]:</span> <span class="c1"># (4)!</span>
</span><span id="__span-21-13"><a href="#__codelineno-21-13" id="__codelineno-21-13" name="__codelineno-21-13"></a>        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>llm_1 is tagged with "joke".</li>
<li>llm_2 is tagged with "poem".</li>
<li>The <code>stream_mode</code> is set to "messages" to stream LLM tokens. The <code>metadata</code> contains information about the LLM invocation, including the tags.</li>
<li>Filter the streamed tokens by the <code>tags</code> field in the metadata to only include the tokens from the LLM invocation with the "joke" tag.</li>
</ol>
<details class="example">
<summary>Extended example: filtering by tags</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-22-1"><a href="#__codelineno-22-1" id="__codelineno-22-1" name="__codelineno-22-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-22-2"><a href="#__codelineno-22-2" id="__codelineno-22-2" name="__codelineno-22-2"></a>
</span><span id="__span-22-3"><a href="#__codelineno-22-3" id="__codelineno-22-3" name="__codelineno-22-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
</span><span id="__span-22-4"><a href="#__codelineno-22-4" id="__codelineno-22-4" name="__codelineno-22-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">START</span><span class="p">,</span> <span class="n">StateGraph</span>
</span><span id="__span-22-5"><a href="#__codelineno-22-5" id="__codelineno-22-5" name="__codelineno-22-5"></a>
</span><span id="__span-22-6"><a href="#__codelineno-22-6" id="__codelineno-22-6" name="__codelineno-22-6"></a><span class="n">joke_model</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"joke"</span><span class="p">])</span> <span class="c1"># (1)!</span>
</span><span id="__span-22-7"><a href="#__codelineno-22-7" id="__codelineno-22-7" name="__codelineno-22-7"></a><span class="n">poem_model</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s2">"poem"</span><span class="p">])</span> <span class="c1"># (2)!</span>
</span><span id="__span-22-8"><a href="#__codelineno-22-8" id="__codelineno-22-8" name="__codelineno-22-8"></a>
</span><span id="__span-22-9"><a href="#__codelineno-22-9" id="__codelineno-22-9" name="__codelineno-22-9"></a>
</span><span id="__span-22-10"><a href="#__codelineno-22-10" id="__codelineno-22-10" name="__codelineno-22-10"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-22-11"><a href="#__codelineno-22-11" id="__codelineno-22-11" name="__codelineno-22-11"></a>      <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-22-12"><a href="#__codelineno-22-12" id="__codelineno-22-12" name="__codelineno-22-12"></a>      <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-22-13"><a href="#__codelineno-22-13" id="__codelineno-22-13" name="__codelineno-22-13"></a>      <span class="n">poem</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-22-14"><a href="#__codelineno-22-14" id="__codelineno-22-14" name="__codelineno-22-14"></a>
</span><span id="__span-22-15"><a href="#__codelineno-22-15" id="__codelineno-22-15" name="__codelineno-22-15"></a>
</span><span id="__span-22-16"><a href="#__codelineno-22-16" id="__codelineno-22-16" name="__codelineno-22-16"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
</span><span id="__span-22-17"><a href="#__codelineno-22-17" id="__codelineno-22-17" name="__codelineno-22-17"></a>      <span class="n">topic</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span>
</span><span id="__span-22-18"><a href="#__codelineno-22-18" id="__codelineno-22-18" name="__codelineno-22-18"></a>      <span class="nb">print</span><span class="p">(</span><span class="s2">"Writing joke..."</span><span class="p">)</span>
</span><span id="__span-22-19"><a href="#__codelineno-22-19" id="__codelineno-22-19" name="__codelineno-22-19"></a>      <span class="c1"># Note: Passing the config through explicitly is required for python &lt; 3.11</span>
</span><span id="__span-22-20"><a href="#__codelineno-22-20" id="__codelineno-22-20" name="__codelineno-22-20"></a>      <span class="c1"># Since context var support wasn't added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks</span>
</span><span id="__span-22-21"><a href="#__codelineno-22-21" id="__codelineno-22-21" name="__codelineno-22-21"></a>      <span class="n">joke_response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">joke_model</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span>
</span><span id="__span-22-22"><a href="#__codelineno-22-22" id="__codelineno-22-22" name="__codelineno-22-22"></a>            <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Write a joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}],</span>
</span><span id="__span-22-23"><a href="#__codelineno-22-23" id="__codelineno-22-23" name="__codelineno-22-23"></a>            <span class="n">config</span><span class="p">,</span> <span class="c1"># (3)!</span>
</span><span id="__span-22-24"><a href="#__codelineno-22-24" id="__codelineno-22-24" name="__codelineno-22-24"></a>      <span class="p">)</span>
</span><span id="__span-22-25"><a href="#__codelineno-22-25" id="__codelineno-22-25" name="__codelineno-22-25"></a>      <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n\n</span><span class="s2">Writing poem..."</span><span class="p">)</span>
</span><span id="__span-22-26"><a href="#__codelineno-22-26" id="__codelineno-22-26" name="__codelineno-22-26"></a>      <span class="n">poem_response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">poem_model</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span>
</span><span id="__span-22-27"><a href="#__codelineno-22-27" id="__codelineno-22-27" name="__codelineno-22-27"></a>            <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Write a short poem about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}],</span>
</span><span id="__span-22-28"><a href="#__codelineno-22-28" id="__codelineno-22-28" name="__codelineno-22-28"></a>            <span class="n">config</span><span class="p">,</span> <span class="c1"># (3)!</span>
</span><span id="__span-22-29"><a href="#__codelineno-22-29" id="__codelineno-22-29" name="__codelineno-22-29"></a>      <span class="p">)</span>
</span><span id="__span-22-30"><a href="#__codelineno-22-30" id="__codelineno-22-30" name="__codelineno-22-30"></a>      <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="n">joke_response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">"poem"</span><span class="p">:</span> <span class="n">poem_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-22-31"><a href="#__codelineno-22-31" id="__codelineno-22-31" name="__codelineno-22-31"></a>
</span><span id="__span-22-32"><a href="#__codelineno-22-32" id="__codelineno-22-32" name="__codelineno-22-32"></a>
</span><span id="__span-22-33"><a href="#__codelineno-22-33" id="__codelineno-22-33" name="__codelineno-22-33"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-22-34"><a href="#__codelineno-22-34" id="__codelineno-22-34" name="__codelineno-22-34"></a>      <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-22-35"><a href="#__codelineno-22-35" id="__codelineno-22-35" name="__codelineno-22-35"></a>      <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">call_model</span><span class="p">)</span>
</span><span id="__span-22-36"><a href="#__codelineno-22-36" id="__codelineno-22-36" name="__codelineno-22-36"></a>      <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"call_model"</span><span class="p">)</span>
</span><span id="__span-22-37"><a href="#__codelineno-22-37" id="__codelineno-22-37" name="__codelineno-22-37"></a>      <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-22-38"><a href="#__codelineno-22-38" id="__codelineno-22-38" name="__codelineno-22-38"></a><span class="p">)</span>
</span><span id="__span-22-39"><a href="#__codelineno-22-39" id="__codelineno-22-39" name="__codelineno-22-39"></a>
</span><span id="__span-22-40"><a href="#__codelineno-22-40" id="__codelineno-22-40" name="__codelineno-22-40"></a><span class="k">async</span> <span class="k">for</span> <span class="n">msg</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-22-41"><a href="#__codelineno-22-41" id="__codelineno-22-41" name="__codelineno-22-41"></a>      <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"cats"</span><span class="p">},</span>
</span><span id="__span-22-42"><a href="#__codelineno-22-42" id="__codelineno-22-42" name="__codelineno-22-42"></a><span class="hll">      <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span> <span class="c1"># (4)!</span>
</span></span><span id="__span-22-43"><a href="#__codelineno-22-43" id="__codelineno-22-43" name="__codelineno-22-43"></a><span class="p">):</span>
</span><span id="__span-22-44"><a href="#__codelineno-22-44" id="__codelineno-22-44" name="__codelineno-22-44"></a>    <span class="k">if</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"tags"</span><span class="p">]</span> <span class="o">==</span> <span class="p">[</span><span class="s2">"joke"</span><span class="p">]:</span> <span class="c1"># (4)!</span>
</span><span id="__span-22-45"><a href="#__codelineno-22-45" id="__codelineno-22-45" name="__codelineno-22-45"></a>        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>The <code>joke_model</code> is tagged with "joke".</li>
<li>The <code>poem_model</code> is tagged with "poem".</li>
<li>The <code>config</code> is passed through explicitly to ensure the context vars are propagated correctly. This is required for Python &lt; 3.11 when using async code. Please see the <a href="#async">async section</a> for more details.</li>
<li>The <code>stream_mode</code> is set to "messages" to stream LLM tokens. The <code>metadata</code> contains information about the LLM invocation, including the tags.</li>
</ol>
</details>
<h4 id="filter-by-node">Filter by node<a class="headerlink" href="#filter-by-node" title="Permanent link">¶</a></h4>
<p>To stream tokens only from specific nodes, use <code>stream_mode="messages"</code> and filter the outputs by the <code>langgraph_node</code> field in the streamed metadata:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-23-1"><a href="#__codelineno-23-1" id="__codelineno-23-1" name="__codelineno-23-1"></a><span class="k">for</span> <span class="n">msg</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span> <span class="c1"># (1)!</span>
</span><span id="__span-23-2"><a href="#__codelineno-23-2" id="__codelineno-23-2" name="__codelineno-23-2"></a>    <span class="n">inputs</span><span class="p">,</span>
</span><span id="__span-23-3"><a href="#__codelineno-23-3" id="__codelineno-23-3" name="__codelineno-23-3"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span>
</span></span><span id="__span-23-4"><a href="#__codelineno-23-4" id="__codelineno-23-4" name="__codelineno-23-4"></a><span class="p">):</span>
</span><span id="__span-23-5"><a href="#__codelineno-23-5" id="__codelineno-23-5" name="__codelineno-23-5"></a><span class="hll">    <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span> <span class="ow">and</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"langgraph_node"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"some_node_name"</span><span class="p">:</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-23-6"><a href="#__codelineno-23-6" id="__codelineno-23-6" name="__codelineno-23-6"></a>        <span class="o">...</span>
</span></code></pre></div>
<ol>
<li>The "messages" stream mode returns a tuple of <code>(message_chunk, metadata)</code> where <code>message_chunk</code> is the token streamed by the LLM and <code>metadata</code> is a dictionary with information about the graph node where the LLM was called and other information.</li>
<li>Filter the streamed tokens by the <code>langgraph_node</code> field in the metadata to only include the tokens from the <code>write_poem</code> node.</li>
</ol>
<details class="example">
<summary>Extended example: streaming LLM tokens from specific nodes</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a href="#__codelineno-24-1" id="__codelineno-24-1" name="__codelineno-24-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-24-2"><a href="#__codelineno-24-2" id="__codelineno-24-2" name="__codelineno-24-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">START</span><span class="p">,</span> <span class="n">StateGraph</span>
</span><span id="__span-24-3"><a href="#__codelineno-24-3" id="__codelineno-24-3" name="__codelineno-24-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
</span><span id="__span-24-4"><a href="#__codelineno-24-4" id="__codelineno-24-4" name="__codelineno-24-4"></a>
</span><span id="__span-24-5"><a href="#__codelineno-24-5" id="__codelineno-24-5" name="__codelineno-24-5"></a><span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"gpt-4o-mini"</span><span class="p">)</span>
</span><span id="__span-24-6"><a href="#__codelineno-24-6" id="__codelineno-24-6" name="__codelineno-24-6"></a>
</span><span id="__span-24-7"><a href="#__codelineno-24-7" id="__codelineno-24-7" name="__codelineno-24-7"></a>
</span><span id="__span-24-8"><a href="#__codelineno-24-8" id="__codelineno-24-8" name="__codelineno-24-8"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-24-9"><a href="#__codelineno-24-9" id="__codelineno-24-9" name="__codelineno-24-9"></a>      <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-24-10"><a href="#__codelineno-24-10" id="__codelineno-24-10" name="__codelineno-24-10"></a>      <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-24-11"><a href="#__codelineno-24-11" id="__codelineno-24-11" name="__codelineno-24-11"></a>      <span class="n">poem</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-24-12"><a href="#__codelineno-24-12" id="__codelineno-24-12" name="__codelineno-24-12"></a>
</span><span id="__span-24-13"><a href="#__codelineno-24-13" id="__codelineno-24-13" name="__codelineno-24-13"></a>
</span><span id="__span-24-14"><a href="#__codelineno-24-14" id="__codelineno-24-14" name="__codelineno-24-14"></a><span class="k">def</span><span class="w"> </span><span class="nf">write_joke</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-24-15"><a href="#__codelineno-24-15" id="__codelineno-24-15" name="__codelineno-24-15"></a>      <span class="n">topic</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span>
</span><span id="__span-24-16"><a href="#__codelineno-24-16" id="__codelineno-24-16" name="__codelineno-24-16"></a>      <span class="n">joke_response</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
</span><span id="__span-24-17"><a href="#__codelineno-24-17" id="__codelineno-24-17" name="__codelineno-24-17"></a>            <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Write a joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}]</span>
</span><span id="__span-24-18"><a href="#__codelineno-24-18" id="__codelineno-24-18" name="__codelineno-24-18"></a>      <span class="p">)</span>
</span><span id="__span-24-19"><a href="#__codelineno-24-19" id="__codelineno-24-19" name="__codelineno-24-19"></a>      <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="n">joke_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-24-20"><a href="#__codelineno-24-20" id="__codelineno-24-20" name="__codelineno-24-20"></a>
</span><span id="__span-24-21"><a href="#__codelineno-24-21" id="__codelineno-24-21" name="__codelineno-24-21"></a>
</span><span id="__span-24-22"><a href="#__codelineno-24-22" id="__codelineno-24-22" name="__codelineno-24-22"></a><span class="k">def</span><span class="w"> </span><span class="nf">write_poem</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-24-23"><a href="#__codelineno-24-23" id="__codelineno-24-23" name="__codelineno-24-23"></a>      <span class="n">topic</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span>
</span><span id="__span-24-24"><a href="#__codelineno-24-24" id="__codelineno-24-24" name="__codelineno-24-24"></a>      <span class="n">poem_response</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span>
</span><span id="__span-24-25"><a href="#__codelineno-24-25" id="__codelineno-24-25" name="__codelineno-24-25"></a>            <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Write a short poem about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}]</span>
</span><span id="__span-24-26"><a href="#__codelineno-24-26" id="__codelineno-24-26" name="__codelineno-24-26"></a>      <span class="p">)</span>
</span><span id="__span-24-27"><a href="#__codelineno-24-27" id="__codelineno-24-27" name="__codelineno-24-27"></a>      <span class="k">return</span> <span class="p">{</span><span class="s2">"poem"</span><span class="p">:</span> <span class="n">poem_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-24-28"><a href="#__codelineno-24-28" id="__codelineno-24-28" name="__codelineno-24-28"></a>
</span><span id="__span-24-29"><a href="#__codelineno-24-29" id="__codelineno-24-29" name="__codelineno-24-29"></a>
</span><span id="__span-24-30"><a href="#__codelineno-24-30" id="__codelineno-24-30" name="__codelineno-24-30"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-24-31"><a href="#__codelineno-24-31" id="__codelineno-24-31" name="__codelineno-24-31"></a>      <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-24-32"><a href="#__codelineno-24-32" id="__codelineno-24-32" name="__codelineno-24-32"></a>      <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">write_joke</span><span class="p">)</span>
</span><span id="__span-24-33"><a href="#__codelineno-24-33" id="__codelineno-24-33" name="__codelineno-24-33"></a>      <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">write_poem</span><span class="p">)</span>
</span><span id="__span-24-34"><a href="#__codelineno-24-34" id="__codelineno-24-34" name="__codelineno-24-34"></a>      <span class="c1"># write both the joke and the poem concurrently</span>
</span><span id="__span-24-35"><a href="#__codelineno-24-35" id="__codelineno-24-35" name="__codelineno-24-35"></a>      <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"write_joke"</span><span class="p">)</span>
</span><span id="__span-24-36"><a href="#__codelineno-24-36" id="__codelineno-24-36" name="__codelineno-24-36"></a>      <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"write_poem"</span><span class="p">)</span>
</span><span id="__span-24-37"><a href="#__codelineno-24-37" id="__codelineno-24-37" name="__codelineno-24-37"></a>      <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-24-38"><a href="#__codelineno-24-38" id="__codelineno-24-38" name="__codelineno-24-38"></a><span class="p">)</span>
</span><span id="__span-24-39"><a href="#__codelineno-24-39" id="__codelineno-24-39" name="__codelineno-24-39"></a>
</span><span id="__span-24-40"><a href="#__codelineno-24-40" id="__codelineno-24-40" name="__codelineno-24-40"></a><span class="hll"><span class="k">for</span> <span class="n">msg</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-24-41"><a href="#__codelineno-24-41" id="__codelineno-24-41" name="__codelineno-24-41"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"cats"</span><span class="p">},</span>
</span><span id="__span-24-42"><a href="#__codelineno-24-42" id="__codelineno-24-42" name="__codelineno-24-42"></a>    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span>
</span><span id="__span-24-43"><a href="#__codelineno-24-43" id="__codelineno-24-43" name="__codelineno-24-43"></a><span class="p">):</span>
</span><span id="__span-24-44"><a href="#__codelineno-24-44" id="__codelineno-24-44" name="__codelineno-24-44"></a><span class="hll">    <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span> <span class="ow">and</span> <span class="n">metadata</span><span class="p">[</span><span class="s2">"langgraph_node"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"write_poem"</span><span class="p">:</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-24-45"><a href="#__codelineno-24-45" id="__codelineno-24-45" name="__codelineno-24-45"></a>        <span class="nb">print</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>The "messages" stream mode returns a tuple of <code>(message_chunk, metadata)</code> where <code>message_chunk</code> is the token streamed by the LLM and <code>metadata</code> is a dictionary with information about the graph node where the LLM was called and other information.</li>
<li>Filter the streamed tokens by the <code>langgraph_node</code> field in the metadata to only include the tokens from the <code>write_poem</code> node.</li>
</ol>
</details>
<h3 id="stream-custom-data">Stream custom data<a class="headerlink" href="#stream-custom-data" title="Permanent link">¶</a></h3>
<p>To send <strong>custom user-defined data</strong> from inside a LangGraph node or tool, follow these steps:</p>
<ol>
<li>Use <code>get_stream_writer()</code> to access the stream writer and emit custom data.</li>
<li>Set <code>stream_mode="custom"</code> when calling <code>.stream()</code> or <code>.astream()</code> to get the custom data in the stream. You can combine multiple modes (e.g., <code>["updates", "custom"]</code>), but at least one must be <code>"custom"</code>.</li>
</ol>
<div class="admonition warning">
<p class="admonition-title">No <code>get_stream_writer()</code> in async for Python &lt; 3.11</p>
<p>In async code running on Python &lt; 3.11, <code>get_stream_writer()</code> will not work.
Instead, add a <code>writer</code> parameter to your node or tool and pass it manually.
See <a href="#async">Async with Python &lt; 3.11</a> for usage examples.</p>
</div>
<div class="tabbed-set tabbed-alternate" data-tabs="8:2"><input checked="checked" id="__tabbed_8_1" name="__tabbed_8" type="radio"/><input id="__tabbed_8_2" name="__tabbed_8" type="radio"/><div class="tabbed-labels"><label for="__tabbed_8_1">node</label><label for="__tabbed_8_2">tool</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-25-1"><a href="#__codelineno-25-1" id="__codelineno-25-1" name="__codelineno-25-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-25-2"><a href="#__codelineno-25-2" id="__codelineno-25-2" name="__codelineno-25-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_stream_writer</span>
</span><span id="__span-25-3"><a href="#__codelineno-25-3" id="__codelineno-25-3" name="__codelineno-25-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span>
</span><span id="__span-25-4"><a href="#__codelineno-25-4" id="__codelineno-25-4" name="__codelineno-25-4"></a>
</span><span id="__span-25-5"><a href="#__codelineno-25-5" id="__codelineno-25-5" name="__codelineno-25-5"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-25-6"><a href="#__codelineno-25-6" id="__codelineno-25-6" name="__codelineno-25-6"></a>    <span class="n">query</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-25-7"><a href="#__codelineno-25-7" id="__codelineno-25-7" name="__codelineno-25-7"></a>    <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-25-8"><a href="#__codelineno-25-8" id="__codelineno-25-8" name="__codelineno-25-8"></a>
</span><span id="__span-25-9"><a href="#__codelineno-25-9" id="__codelineno-25-9" name="__codelineno-25-9"></a><span class="k">def</span><span class="w"> </span><span class="nf">node</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-25-10"><a href="#__codelineno-25-10" id="__codelineno-25-10" name="__codelineno-25-10"></a>    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span>  <span class="c1"># (1)!</span>
</span><span id="__span-25-11"><a href="#__codelineno-25-11" id="__codelineno-25-11" name="__codelineno-25-11"></a>    <span class="n">writer</span><span class="p">({</span><span class="s2">"custom_key"</span><span class="p">:</span> <span class="s2">"Generating custom data inside node"</span><span class="p">})</span> <span class="c1"># (2)!</span>
</span><span id="__span-25-12"><a href="#__codelineno-25-12" id="__codelineno-25-12" name="__codelineno-25-12"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"answer"</span><span class="p">:</span> <span class="s2">"some data"</span><span class="p">}</span>
</span><span id="__span-25-13"><a href="#__codelineno-25-13" id="__codelineno-25-13" name="__codelineno-25-13"></a>
</span><span id="__span-25-14"><a href="#__codelineno-25-14" id="__codelineno-25-14" name="__codelineno-25-14"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-25-15"><a href="#__codelineno-25-15" id="__codelineno-25-15" name="__codelineno-25-15"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-25-16"><a href="#__codelineno-25-16" id="__codelineno-25-16" name="__codelineno-25-16"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
</span><span id="__span-25-17"><a href="#__codelineno-25-17" id="__codelineno-25-17" name="__codelineno-25-17"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"node"</span><span class="p">)</span>
</span><span id="__span-25-18"><a href="#__codelineno-25-18" id="__codelineno-25-18" name="__codelineno-25-18"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-25-19"><a href="#__codelineno-25-19" id="__codelineno-25-19" name="__codelineno-25-19"></a><span class="p">)</span>
</span><span id="__span-25-20"><a href="#__codelineno-25-20" id="__codelineno-25-20" name="__codelineno-25-20"></a>
</span><span id="__span-25-21"><a href="#__codelineno-25-21" id="__codelineno-25-21" name="__codelineno-25-21"></a><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"query"</span><span class="p">:</span> <span class="s2">"example"</span><span class="p">}</span>
</span><span id="__span-25-22"><a href="#__codelineno-25-22" id="__codelineno-25-22" name="__codelineno-25-22"></a>
</span><span id="__span-25-23"><a href="#__codelineno-25-23" id="__codelineno-25-23" name="__codelineno-25-23"></a><span class="c1"># Usage</span>
</span><span id="__span-25-24"><a href="#__codelineno-25-24" id="__codelineno-25-24" name="__codelineno-25-24"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span><span class="p">):</span>  <span class="c1"># (3)!</span>
</span><span id="__span-25-25"><a href="#__codelineno-25-25" id="__codelineno-25-25" name="__codelineno-25-25"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Get the stream writer to send custom data.</li>
<li>Emit a custom key-value pair (e.g., progress update).</li>
<li>Set <code>stream_mode="custom"</code> to receive the custom data in the stream.</li>
</ol>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-26-1"><a href="#__codelineno-26-1" id="__codelineno-26-1" name="__codelineno-26-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_core.tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">tool</span>
</span><span id="__span-26-2"><a href="#__codelineno-26-2" id="__codelineno-26-2" name="__codelineno-26-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_stream_writer</span>
</span><span id="__span-26-3"><a href="#__codelineno-26-3" id="__codelineno-26-3" name="__codelineno-26-3"></a>
</span><span id="__span-26-4"><a href="#__codelineno-26-4" id="__codelineno-26-4" name="__codelineno-26-4"></a><span class="nd">@tool</span>
</span><span id="__span-26-5"><a href="#__codelineno-26-5" id="__codelineno-26-5" name="__codelineno-26-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">query_database</span><span class="p">(</span><span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="__span-26-6"><a href="#__codelineno-26-6" id="__codelineno-26-6" name="__codelineno-26-6"></a><span class="w">    </span><span class="sd">"""Query the database."""</span>
</span><span id="__span-26-7"><a href="#__codelineno-26-7" id="__codelineno-26-7" name="__codelineno-26-7"></a>    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span> <span class="c1"># (1)!</span>
</span><span id="__span-26-8"><a href="#__codelineno-26-8" id="__codelineno-26-8" name="__codelineno-26-8"></a><span class="hll">    <span class="n">writer</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="s2">"Retrieved 0/100 records"</span><span class="p">,</span> <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"progress"</span><span class="p">})</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-26-9"><a href="#__codelineno-26-9" id="__codelineno-26-9" name="__codelineno-26-9"></a>    <span class="c1"># perform query</span>
</span><span id="__span-26-10"><a href="#__codelineno-26-10" id="__codelineno-26-10" name="__codelineno-26-10"></a><span class="hll">    <span class="n">writer</span><span class="p">({</span><span class="s2">"data"</span><span class="p">:</span> <span class="s2">"Retrieved 100/100 records"</span><span class="p">,</span> <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"progress"</span><span class="p">})</span> <span class="c1"># (3)!</span>
</span></span><span id="__span-26-11"><a href="#__codelineno-26-11" id="__codelineno-26-11" name="__codelineno-26-11"></a>    <span class="k">return</span> <span class="s2">"some-answer"</span>
</span><span id="__span-26-12"><a href="#__codelineno-26-12" id="__codelineno-26-12" name="__codelineno-26-12"></a>
</span><span id="__span-26-13"><a href="#__codelineno-26-13" id="__codelineno-26-13" name="__codelineno-26-13"></a>
</span><span id="__span-26-14"><a href="#__codelineno-26-14" id="__codelineno-26-14" name="__codelineno-26-14"></a><span class="n">graph</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># define a graph that uses this tool</span>
</span><span id="__span-26-15"><a href="#__codelineno-26-15" id="__codelineno-26-15" name="__codelineno-26-15"></a>
</span><span id="__span-26-16"><a href="#__codelineno-26-16" id="__codelineno-26-16" name="__codelineno-26-16"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span><span class="p">):</span> <span class="c1"># (4)!</span>
</span><span id="__span-26-17"><a href="#__codelineno-26-17" id="__codelineno-26-17" name="__codelineno-26-17"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Access the stream writer to send custom data.</li>
<li>Emit a custom key-value pair (e.g., progress update).</li>
<li>Emit another custom key-value pair.</li>
<li>Set <code>stream_mode="custom"</code> to receive the custom data in the stream.</li>
</ol>
</div>
</div>
</div>
<h3 id="use-with-any-llm">Use with any LLM<a class="headerlink" href="#use-with-any-llm" title="Permanent link">¶</a></h3>
<p>You can use <code>stream_mode="custom"</code> to stream data from <strong>any LLM API</strong> — even if that API does <strong>not</strong> implement the LangChain chat model interface.</p>
<p>This lets you integrate raw LLM clients or external services that provide their own streaming interfaces, making LangGraph highly flexible for custom setups.</p>
<p><sup><i>API Reference: <a href="https://langchain-ai.github.io/langgraph/reference/config/#langgraph.config.get_stream_writer">get_stream_writer</a></i></sup></p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-27-1"><a href="#__codelineno-27-1" id="__codelineno-27-1" name="__codelineno-27-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_stream_writer</span>
</span><span id="__span-27-2"><a href="#__codelineno-27-2" id="__codelineno-27-2" name="__codelineno-27-2"></a>
</span><span id="__span-27-3"><a href="#__codelineno-27-3" id="__codelineno-27-3" name="__codelineno-27-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">call_arbitrary_model</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
</span><span id="__span-27-4"><a href="#__codelineno-27-4" id="__codelineno-27-4" name="__codelineno-27-4"></a><span class="w">    </span><span class="sd">"""Example node that calls an arbitrary model and streams the output"""</span>
</span><span id="__span-27-5"><a href="#__codelineno-27-5" id="__codelineno-27-5" name="__codelineno-27-5"></a><span class="hll">    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-27-6"><a href="#__codelineno-27-6" id="__codelineno-27-6" name="__codelineno-27-6"></a>    <span class="c1"># Assume you have a streaming client that yields chunks</span>
</span><span id="__span-27-7"><a href="#__codelineno-27-7" id="__codelineno-27-7" name="__codelineno-27-7"></a>    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">your_custom_streaming_client</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]):</span> <span class="c1"># (2)!</span>
</span><span id="__span-27-8"><a href="#__codelineno-27-8" id="__codelineno-27-8" name="__codelineno-27-8"></a><span class="hll">        <span class="n">writer</span><span class="p">({</span><span class="s2">"custom_llm_chunk"</span><span class="p">:</span> <span class="n">chunk</span><span class="p">})</span> <span class="c1"># (3)!</span>
</span></span><span id="__span-27-9"><a href="#__codelineno-27-9" id="__codelineno-27-9" name="__codelineno-27-9"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"result"</span><span class="p">:</span> <span class="s2">"completed"</span><span class="p">}</span>
</span><span id="__span-27-10"><a href="#__codelineno-27-10" id="__codelineno-27-10" name="__codelineno-27-10"></a>
</span><span id="__span-27-11"><a href="#__codelineno-27-11" id="__codelineno-27-11" name="__codelineno-27-11"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-27-12"><a href="#__codelineno-27-12" id="__codelineno-27-12" name="__codelineno-27-12"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-27-13"><a href="#__codelineno-27-13" id="__codelineno-27-13" name="__codelineno-27-13"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">call_arbitrary_model</span><span class="p">)</span>
</span><span id="__span-27-14"><a href="#__codelineno-27-14" id="__codelineno-27-14" name="__codelineno-27-14"></a>    <span class="c1"># Add other nodes and edges as needed</span>
</span><span id="__span-27-15"><a href="#__codelineno-27-15" id="__codelineno-27-15" name="__codelineno-27-15"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-27-16"><a href="#__codelineno-27-16" id="__codelineno-27-16" name="__codelineno-27-16"></a><span class="p">)</span>
</span><span id="__span-27-17"><a href="#__codelineno-27-17" id="__codelineno-27-17" name="__codelineno-27-17"></a>
</span><span id="__span-27-18"><a href="#__codelineno-27-18" id="__codelineno-27-18" name="__codelineno-27-18"></a><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
</span><span id="__span-27-19"><a href="#__codelineno-27-19" id="__codelineno-27-19" name="__codelineno-27-19"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"cats"</span><span class="p">},</span>
</span><span id="__span-27-20"><a href="#__codelineno-27-20" id="__codelineno-27-20" name="__codelineno-27-20"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span><span class="p">,</span> <span class="c1"># (4)!</span>
</span></span><span id="__span-27-21"><a href="#__codelineno-27-21" id="__codelineno-27-21" name="__codelineno-27-21"></a><span class="p">):</span>
</span><span id="__span-27-22"><a href="#__codelineno-27-22" id="__codelineno-27-22" name="__codelineno-27-22"></a>    <span class="c1"># The chunk will contain the custom data streamed from the llm</span>
</span><span id="__span-27-23"><a href="#__codelineno-27-23" id="__codelineno-27-23" name="__codelineno-27-23"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Get the stream writer to send custom data.</li>
<li>Generate LLM tokens using your custom streaming client.</li>
<li>Use the writer to send custom data to the stream.</li>
<li>Set <code>stream_mode="custom"</code> to receive the custom data in the stream.</li>
</ol>
<details class="example">
<summary>Extended example: streaming arbitrary chat model</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-28-1"><a href="#__codelineno-28-1" id="__codelineno-28-1" name="__codelineno-28-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">operator</span>
</span><span id="__span-28-2"><a href="#__codelineno-28-2" id="__codelineno-28-2" name="__codelineno-28-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
</span><span id="__span-28-3"><a href="#__codelineno-28-3" id="__codelineno-28-3" name="__codelineno-28-3"></a>
</span><span id="__span-28-4"><a href="#__codelineno-28-4" id="__codelineno-28-4" name="__codelineno-28-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-28-5"><a href="#__codelineno-28-5" id="__codelineno-28-5" name="__codelineno-28-5"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Annotated</span>
</span><span id="__span-28-6"><a href="#__codelineno-28-6" id="__codelineno-28-6" name="__codelineno-28-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">StateGraph</span><span class="p">,</span> <span class="n">START</span>
</span><span id="__span-28-7"><a href="#__codelineno-28-7" id="__codelineno-28-7" name="__codelineno-28-7"></a>
</span><span id="__span-28-8"><a href="#__codelineno-28-8" id="__codelineno-28-8" name="__codelineno-28-8"></a><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AsyncOpenAI</span>
</span><span id="__span-28-9"><a href="#__codelineno-28-9" id="__codelineno-28-9" name="__codelineno-28-9"></a>
</span><span id="__span-28-10"><a href="#__codelineno-28-10" id="__codelineno-28-10" name="__codelineno-28-10"></a><span class="n">openai_client</span> <span class="o">=</span> <span class="n">AsyncOpenAI</span><span class="p">()</span>
</span><span id="__span-28-11"><a href="#__codelineno-28-11" id="__codelineno-28-11" name="__codelineno-28-11"></a><span class="n">model_name</span> <span class="o">=</span> <span class="s2">"gpt-4o-mini"</span>
</span><span id="__span-28-12"><a href="#__codelineno-28-12" id="__codelineno-28-12" name="__codelineno-28-12"></a>
</span><span id="__span-28-13"><a href="#__codelineno-28-13" id="__codelineno-28-13" name="__codelineno-28-13"></a>
</span><span id="__span-28-14"><a href="#__codelineno-28-14" id="__codelineno-28-14" name="__codelineno-28-14"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">stream_tokens</span><span class="p">(</span><span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]):</span>
</span><span id="__span-28-15"><a href="#__codelineno-28-15" id="__codelineno-28-15" name="__codelineno-28-15"></a>    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">openai_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="__span-28-16"><a href="#__codelineno-28-16" id="__codelineno-28-16" name="__codelineno-28-16"></a>        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-28-17"><a href="#__codelineno-28-17" id="__codelineno-28-17" name="__codelineno-28-17"></a>    <span class="p">)</span>
</span><span id="__span-28-18"><a href="#__codelineno-28-18" id="__codelineno-28-18" name="__codelineno-28-18"></a>    <span class="n">role</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-28-19"><a href="#__codelineno-28-19" id="__codelineno-28-19" name="__codelineno-28-19"></a>    <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
</span><span id="__span-28-20"><a href="#__codelineno-28-20" id="__codelineno-28-20" name="__codelineno-28-20"></a>        <span class="n">delta</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span>
</span><span id="__span-28-21"><a href="#__codelineno-28-21" id="__codelineno-28-21" name="__codelineno-28-21"></a>
</span><span id="__span-28-22"><a href="#__codelineno-28-22" id="__codelineno-28-22" name="__codelineno-28-22"></a>        <span class="k">if</span> <span class="n">delta</span><span class="o">.</span><span class="n">role</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-28-23"><a href="#__codelineno-28-23" id="__codelineno-28-23" name="__codelineno-28-23"></a>            <span class="n">role</span> <span class="o">=</span> <span class="n">delta</span><span class="o">.</span><span class="n">role</span>
</span><span id="__span-28-24"><a href="#__codelineno-28-24" id="__codelineno-28-24" name="__codelineno-28-24"></a>
</span><span id="__span-28-25"><a href="#__codelineno-28-25" id="__codelineno-28-25" name="__codelineno-28-25"></a>        <span class="k">if</span> <span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
</span><span id="__span-28-26"><a href="#__codelineno-28-26" id="__codelineno-28-26" name="__codelineno-28-26"></a>            <span class="k">yield</span> <span class="p">{</span><span class="s2">"role"</span><span class="p">:</span> <span class="n">role</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-28-27"><a href="#__codelineno-28-27" id="__codelineno-28-27" name="__codelineno-28-27"></a>
</span><span id="__span-28-28"><a href="#__codelineno-28-28" id="__codelineno-28-28" name="__codelineno-28-28"></a>
</span><span id="__span-28-29"><a href="#__codelineno-28-29" id="__codelineno-28-29" name="__codelineno-28-29"></a><span class="c1"># this is our tool</span>
</span><span id="__span-28-30"><a href="#__codelineno-28-30" id="__codelineno-28-30" name="__codelineno-28-30"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">get_items</span><span class="p">(</span><span class="n">place</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="__span-28-31"><a href="#__codelineno-28-31" id="__codelineno-28-31" name="__codelineno-28-31"></a><span class="w">    </span><span class="sd">"""Use this tool to list items one might find in a place you're asked about."""</span>
</span><span id="__span-28-32"><a href="#__codelineno-28-32" id="__codelineno-28-32" name="__codelineno-28-32"></a>    <span class="n">writer</span> <span class="o">=</span> <span class="n">get_stream_writer</span><span class="p">()</span>
</span><span id="__span-28-33"><a href="#__codelineno-28-33" id="__codelineno-28-33" name="__codelineno-28-33"></a>    <span class="n">response</span> <span class="o">=</span> <span class="s2">""</span>
</span><span id="__span-28-34"><a href="#__codelineno-28-34" id="__codelineno-28-34" name="__codelineno-28-34"></a>    <span class="k">async</span> <span class="k">for</span> <span class="n">msg_chunk</span> <span class="ow">in</span> <span class="n">stream_tokens</span><span class="p">(</span>
</span><span id="__span-28-35"><a href="#__codelineno-28-35" id="__codelineno-28-35" name="__codelineno-28-35"></a>        <span class="n">model_name</span><span class="p">,</span>
</span><span id="__span-28-36"><a href="#__codelineno-28-36" id="__codelineno-28-36" name="__codelineno-28-36"></a>        <span class="p">[</span>
</span><span id="__span-28-37"><a href="#__codelineno-28-37" id="__codelineno-28-37" name="__codelineno-28-37"></a>            <span class="p">{</span>
</span><span id="__span-28-38"><a href="#__codelineno-28-38" id="__codelineno-28-38" name="__codelineno-28-38"></a>                <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span>
</span><span id="__span-28-39"><a href="#__codelineno-28-39" id="__codelineno-28-39" name="__codelineno-28-39"></a>                <span class="s2">"content"</span><span class="p">:</span> <span class="p">(</span>
</span><span id="__span-28-40"><a href="#__codelineno-28-40" id="__codelineno-28-40" name="__codelineno-28-40"></a>                    <span class="s2">"Can you tell me what kind of items "</span>
</span><span id="__span-28-41"><a href="#__codelineno-28-41" id="__codelineno-28-41" name="__codelineno-28-41"></a>                    <span class="sa">f</span><span class="s2">"i might find in the following place: '</span><span class="si">{</span><span class="n">place</span><span class="si">}</span><span class="s2">'. "</span>
</span><span id="__span-28-42"><a href="#__codelineno-28-42" id="__codelineno-28-42" name="__codelineno-28-42"></a>                    <span class="s2">"List at least 3 such items separating them by a comma. "</span>
</span><span id="__span-28-43"><a href="#__codelineno-28-43" id="__codelineno-28-43" name="__codelineno-28-43"></a>                    <span class="s2">"And include a brief description of each item."</span>
</span><span id="__span-28-44"><a href="#__codelineno-28-44" id="__codelineno-28-44" name="__codelineno-28-44"></a>                <span class="p">),</span>
</span><span id="__span-28-45"><a href="#__codelineno-28-45" id="__codelineno-28-45" name="__codelineno-28-45"></a>            <span class="p">}</span>
</span><span id="__span-28-46"><a href="#__codelineno-28-46" id="__codelineno-28-46" name="__codelineno-28-46"></a>        <span class="p">],</span>
</span><span id="__span-28-47"><a href="#__codelineno-28-47" id="__codelineno-28-47" name="__codelineno-28-47"></a>    <span class="p">):</span>
</span><span id="__span-28-48"><a href="#__codelineno-28-48" id="__codelineno-28-48" name="__codelineno-28-48"></a>        <span class="n">response</span> <span class="o">+=</span> <span class="n">msg_chunk</span><span class="p">[</span><span class="s2">"content"</span><span class="p">]</span>
</span><span id="__span-28-49"><a href="#__codelineno-28-49" id="__codelineno-28-49" name="__codelineno-28-49"></a>        <span class="n">writer</span><span class="p">(</span><span class="n">msg_chunk</span><span class="p">)</span>
</span><span id="__span-28-50"><a href="#__codelineno-28-50" id="__codelineno-28-50" name="__codelineno-28-50"></a>
</span><span id="__span-28-51"><a href="#__codelineno-28-51" id="__codelineno-28-51" name="__codelineno-28-51"></a>    <span class="k">return</span> <span class="n">response</span>
</span><span id="__span-28-52"><a href="#__codelineno-28-52" id="__codelineno-28-52" name="__codelineno-28-52"></a>
</span><span id="__span-28-53"><a href="#__codelineno-28-53" id="__codelineno-28-53" name="__codelineno-28-53"></a>
</span><span id="__span-28-54"><a href="#__codelineno-28-54" id="__codelineno-28-54" name="__codelineno-28-54"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-28-55"><a href="#__codelineno-28-55" id="__codelineno-28-55" name="__codelineno-28-55"></a>    <span class="n">messages</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">operator</span><span class="o">.</span><span class="n">add</span><span class="p">]</span>
</span><span id="__span-28-56"><a href="#__codelineno-28-56" id="__codelineno-28-56" name="__codelineno-28-56"></a>
</span><span id="__span-28-57"><a href="#__codelineno-28-57" id="__codelineno-28-57" name="__codelineno-28-57"></a>
</span><span id="__span-28-58"><a href="#__codelineno-28-58" id="__codelineno-28-58" name="__codelineno-28-58"></a><span class="c1"># this is the tool-calling graph node</span>
</span><span id="__span-28-59"><a href="#__codelineno-28-59" id="__codelineno-28-59" name="__codelineno-28-59"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_tool</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">):</span>
</span><span id="__span-28-60"><a href="#__codelineno-28-60" id="__codelineno-28-60" name="__codelineno-28-60"></a>    <span class="n">ai_message</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"messages"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-28-61"><a href="#__codelineno-28-61" id="__codelineno-28-61" name="__codelineno-28-61"></a>    <span class="n">tool_call</span> <span class="o">=</span> <span class="n">ai_message</span><span class="p">[</span><span class="s2">"tool_calls"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-28-62"><a href="#__codelineno-28-62" id="__codelineno-28-62" name="__codelineno-28-62"></a>
</span><span id="__span-28-63"><a href="#__codelineno-28-63" id="__codelineno-28-63" name="__codelineno-28-63"></a>    <span class="n">function_name</span> <span class="o">=</span> <span class="n">tool_call</span><span class="p">[</span><span class="s2">"function"</span><span class="p">][</span><span class="s2">"name"</span><span class="p">]</span>
</span><span id="__span-28-64"><a href="#__codelineno-28-64" id="__codelineno-28-64" name="__codelineno-28-64"></a>    <span class="k">if</span> <span class="n">function_name</span> <span class="o">!=</span> <span class="s2">"get_items"</span><span class="p">:</span>
</span><span id="__span-28-65"><a href="#__codelineno-28-65" id="__codelineno-28-65" name="__codelineno-28-65"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tool </span><span class="si">{</span><span class="n">function_name</span><span class="si">}</span><span class="s2"> not supported"</span><span class="p">)</span>
</span><span id="__span-28-66"><a href="#__codelineno-28-66" id="__codelineno-28-66" name="__codelineno-28-66"></a>
</span><span id="__span-28-67"><a href="#__codelineno-28-67" id="__codelineno-28-67" name="__codelineno-28-67"></a>    <span class="n">function_arguments</span> <span class="o">=</span> <span class="n">tool_call</span><span class="p">[</span><span class="s2">"function"</span><span class="p">][</span><span class="s2">"arguments"</span><span class="p">]</span>
</span><span id="__span-28-68"><a href="#__codelineno-28-68" id="__codelineno-28-68" name="__codelineno-28-68"></a>    <span class="n">arguments</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">function_arguments</span><span class="p">)</span>
</span><span id="__span-28-69"><a href="#__codelineno-28-69" id="__codelineno-28-69" name="__codelineno-28-69"></a>
</span><span id="__span-28-70"><a href="#__codelineno-28-70" id="__codelineno-28-70" name="__codelineno-28-70"></a>    <span class="n">function_response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">get_items</span><span class="p">(</span><span class="o">**</span><span class="n">arguments</span><span class="p">)</span>
</span><span id="__span-28-71"><a href="#__codelineno-28-71" id="__codelineno-28-71" name="__codelineno-28-71"></a>    <span class="n">tool_message</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-28-72"><a href="#__codelineno-28-72" id="__codelineno-28-72" name="__codelineno-28-72"></a>        <span class="s2">"tool_call_id"</span><span class="p">:</span> <span class="n">tool_call</span><span class="p">[</span><span class="s2">"id"</span><span class="p">],</span>
</span><span id="__span-28-73"><a href="#__codelineno-28-73" id="__codelineno-28-73" name="__codelineno-28-73"></a>        <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"tool"</span><span class="p">,</span>
</span><span id="__span-28-74"><a href="#__codelineno-28-74" id="__codelineno-28-74" name="__codelineno-28-74"></a>        <span class="s2">"name"</span><span class="p">:</span> <span class="n">function_name</span><span class="p">,</span>
</span><span id="__span-28-75"><a href="#__codelineno-28-75" id="__codelineno-28-75" name="__codelineno-28-75"></a>        <span class="s2">"content"</span><span class="p">:</span> <span class="n">function_response</span><span class="p">,</span>
</span><span id="__span-28-76"><a href="#__codelineno-28-76" id="__codelineno-28-76" name="__codelineno-28-76"></a>    <span class="p">}</span>
</span><span id="__span-28-77"><a href="#__codelineno-28-77" id="__codelineno-28-77" name="__codelineno-28-77"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"messages"</span><span class="p">:</span> <span class="p">[</span><span class="n">tool_message</span><span class="p">]}</span>
</span><span id="__span-28-78"><a href="#__codelineno-28-78" id="__codelineno-28-78" name="__codelineno-28-78"></a>
</span><span id="__span-28-79"><a href="#__codelineno-28-79" id="__codelineno-28-79" name="__codelineno-28-79"></a>
</span><span id="__span-28-80"><a href="#__codelineno-28-80" id="__codelineno-28-80" name="__codelineno-28-80"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-28-81"><a href="#__codelineno-28-81" id="__codelineno-28-81" name="__codelineno-28-81"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-28-82"><a href="#__codelineno-28-82" id="__codelineno-28-82" name="__codelineno-28-82"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">call_tool</span><span class="p">)</span>
</span><span id="__span-28-83"><a href="#__codelineno-28-83" id="__codelineno-28-83" name="__codelineno-28-83"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"call_tool"</span><span class="p">)</span>
</span><span id="__span-28-84"><a href="#__codelineno-28-84" id="__codelineno-28-84" name="__codelineno-28-84"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-28-85"><a href="#__codelineno-28-85" id="__codelineno-28-85" name="__codelineno-28-85"></a><span class="p">)</span>
</span></code></pre></div>
<p>Let's invoke the graph with an AI message that includes a tool call:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-29-1"><a href="#__codelineno-29-1" id="__codelineno-29-1" name="__codelineno-29-1"></a><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-29-2"><a href="#__codelineno-29-2" id="__codelineno-29-2" name="__codelineno-29-2"></a>    <span class="s2">"messages"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="__span-29-3"><a href="#__codelineno-29-3" id="__codelineno-29-3" name="__codelineno-29-3"></a>        <span class="p">{</span>
</span><span id="__span-29-4"><a href="#__codelineno-29-4" id="__codelineno-29-4" name="__codelineno-29-4"></a>            <span class="s2">"content"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-29-5"><a href="#__codelineno-29-5" id="__codelineno-29-5" name="__codelineno-29-5"></a>            <span class="s2">"role"</span><span class="p">:</span> <span class="s2">"assistant"</span><span class="p">,</span>
</span><span id="__span-29-6"><a href="#__codelineno-29-6" id="__codelineno-29-6" name="__codelineno-29-6"></a>            <span class="s2">"tool_calls"</span><span class="p">:</span> <span class="p">[</span>
</span><span id="__span-29-7"><a href="#__codelineno-29-7" id="__codelineno-29-7" name="__codelineno-29-7"></a>                <span class="p">{</span>
</span><span id="__span-29-8"><a href="#__codelineno-29-8" id="__codelineno-29-8" name="__codelineno-29-8"></a>                    <span class="s2">"id"</span><span class="p">:</span> <span class="s2">"1"</span><span class="p">,</span>
</span><span id="__span-29-9"><a href="#__codelineno-29-9" id="__codelineno-29-9" name="__codelineno-29-9"></a>                    <span class="s2">"function"</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-29-10"><a href="#__codelineno-29-10" id="__codelineno-29-10" name="__codelineno-29-10"></a>                        <span class="s2">"arguments"</span><span class="p">:</span> <span class="s1">'{"place":"bedroom"}'</span><span class="p">,</span>
</span><span id="__span-29-11"><a href="#__codelineno-29-11" id="__codelineno-29-11" name="__codelineno-29-11"></a>                        <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"get_items"</span><span class="p">,</span>
</span><span id="__span-29-12"><a href="#__codelineno-29-12" id="__codelineno-29-12" name="__codelineno-29-12"></a>                    <span class="p">},</span>
</span><span id="__span-29-13"><a href="#__codelineno-29-13" id="__codelineno-29-13" name="__codelineno-29-13"></a>                    <span class="s2">"type"</span><span class="p">:</span> <span class="s2">"function"</span><span class="p">,</span>
</span><span id="__span-29-14"><a href="#__codelineno-29-14" id="__codelineno-29-14" name="__codelineno-29-14"></a>                <span class="p">}</span>
</span><span id="__span-29-15"><a href="#__codelineno-29-15" id="__codelineno-29-15" name="__codelineno-29-15"></a>            <span class="p">],</span>
</span><span id="__span-29-16"><a href="#__codelineno-29-16" id="__codelineno-29-16" name="__codelineno-29-16"></a>        <span class="p">}</span>
</span><span id="__span-29-17"><a href="#__codelineno-29-17" id="__codelineno-29-17" name="__codelineno-29-17"></a>    <span class="p">]</span>
</span><span id="__span-29-18"><a href="#__codelineno-29-18" id="__codelineno-29-18" name="__codelineno-29-18"></a><span class="p">}</span>
</span><span id="__span-29-19"><a href="#__codelineno-29-19" id="__codelineno-29-19" name="__codelineno-29-19"></a>
</span><span id="__span-29-20"><a href="#__codelineno-29-20" id="__codelineno-29-20" name="__codelineno-29-20"></a><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-29-21"><a href="#__codelineno-29-21" id="__codelineno-29-21" name="__codelineno-29-21"></a>    <span class="n">inputs</span><span class="p">,</span>
</span><span id="__span-29-22"><a href="#__codelineno-29-22" id="__codelineno-29-22" name="__codelineno-29-22"></a>    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span><span class="p">,</span>
</span><span id="__span-29-23"><a href="#__codelineno-29-23" id="__codelineno-29-23" name="__codelineno-29-23"></a><span class="p">):</span>
</span><span id="__span-29-24"><a href="#__codelineno-29-24" id="__codelineno-29-24" name="__codelineno-29-24"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="s2">"content"</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
</details>
<h3 id="disable-streaming-for-specific-chat-models">Disable streaming for specific chat models<a class="headerlink" href="#disable-streaming-for-specific-chat-models" title="Permanent link">¶</a></h3>
<p>If your application mixes models that support streaming with those that do not, you may need to explicitly disable streaming for
models that do not support it.</p>
<p>Set <code>disable_streaming=True</code> when initializing the model.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="9:2"><input checked="checked" id="__tabbed_9_1" name="__tabbed_9" type="radio"/><input id="__tabbed_9_2" name="__tabbed_9" type="radio"/><div class="tabbed-labels"><label for="__tabbed_9_1">init_chat_model</label><label for="__tabbed_9_2">chat model interface</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-30-1"><a href="#__codelineno-30-1" id="__codelineno-30-1" name="__codelineno-30-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
</span><span id="__span-30-2"><a href="#__codelineno-30-2" id="__codelineno-30-2" name="__codelineno-30-2"></a>
</span><span id="__span-30-3"><a href="#__codelineno-30-3" id="__codelineno-30-3" name="__codelineno-30-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span>
</span><span id="__span-30-4"><a href="#__codelineno-30-4" id="__codelineno-30-4" name="__codelineno-30-4"></a>    <span class="s2">"anthropic:claude-3-7-sonnet-latest"</span><span class="p">,</span>
</span><span id="__span-30-5"><a href="#__codelineno-30-5" id="__codelineno-30-5" name="__codelineno-30-5"></a><span class="hll">    <span class="n">disable_streaming</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-30-6"><a href="#__codelineno-30-6" id="__codelineno-30-6" name="__codelineno-30-6"></a><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Set <code>disable_streaming=True</code> to disable streaming for the chat model.</li>
</ol>
</div>
<div class="tabbed-block">
<div class="language-python highlight"><pre><span></span><code><span id="__span-31-1"><a href="#__codelineno-31-1" id="__codelineno-31-1" name="__codelineno-31-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
</span><span id="__span-31-2"><a href="#__codelineno-31-2" id="__codelineno-31-2" name="__codelineno-31-2"></a>
</span><span id="__span-31-3"><a href="#__codelineno-31-3" id="__codelineno-31-3" name="__codelineno-31-3"></a><span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"o1-preview"</span><span class="p">,</span> <span class="n">disable_streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># (1)!</span>
</span></code></pre></div>
<ol>
<li>Set <code>disable_streaming=True</code> to disable streaming for the chat model.</li>
</ol>
</div>
</div>
</div>
<h3 id="async">Async with Python &lt; 3.11<a class="headerlink" href="#async" title="Permanent link">¶</a></h3>
<p>In Python versions &lt; 3.11, <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task">asyncio tasks</a> do not support the <code>context</code> parameter.<br/>
This limits LangGraph ability to automatically propagate context, and affects LangGraph's streaming mechanisms in two key ways:</p>
<ol>
<li>You <strong>must</strong> explicitly pass <a href="https://python.langchain.com/docs/concepts/runnables/#runnableconfig"><code>RunnableConfig</code></a> into async LLM calls (e.g., <code>ainvoke()</code>), as callbacks are not automatically propagated.</li>
<li>You <strong>cannot</strong> use <code>get_stream_writer()</code> in async nodes or tools — you must pass a <code>writer</code> argument directly.</li>
</ol>
<details class="example">
<summary>Extended example: async LLM call with manual config</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-32-1"><a href="#__codelineno-32-1" id="__codelineno-32-1" name="__codelineno-32-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-32-2"><a href="#__codelineno-32-2" id="__codelineno-32-2" name="__codelineno-32-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.graph</span><span class="w"> </span><span class="kn">import</span> <span class="n">START</span><span class="p">,</span> <span class="n">StateGraph</span>
</span><span id="__span-32-3"><a href="#__codelineno-32-3" id="__codelineno-32-3" name="__codelineno-32-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.chat_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_chat_model</span>
</span><span id="__span-32-4"><a href="#__codelineno-32-4" id="__codelineno-32-4" name="__codelineno-32-4"></a>
</span><span id="__span-32-5"><a href="#__codelineno-32-5" id="__codelineno-32-5" name="__codelineno-32-5"></a><span class="n">llm</span> <span class="o">=</span> <span class="n">init_chat_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai:gpt-4o-mini"</span><span class="p">)</span>
</span><span id="__span-32-6"><a href="#__codelineno-32-6" id="__codelineno-32-6" name="__codelineno-32-6"></a>
</span><span id="__span-32-7"><a href="#__codelineno-32-7" id="__codelineno-32-7" name="__codelineno-32-7"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-32-8"><a href="#__codelineno-32-8" id="__codelineno-32-8" name="__codelineno-32-8"></a>    <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-32-9"><a href="#__codelineno-32-9" id="__codelineno-32-9" name="__codelineno-32-9"></a>    <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-32-10"><a href="#__codelineno-32-10" id="__codelineno-32-10" name="__codelineno-32-10"></a>
</span><span id="__span-32-11"><a href="#__codelineno-32-11" id="__codelineno-32-11" name="__codelineno-32-11"></a><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_model</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span> <span class="c1"># (1)!</span>
</span><span id="__span-32-12"><a href="#__codelineno-32-12" id="__codelineno-32-12" name="__codelineno-32-12"></a>    <span class="n">topic</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">"topic"</span><span class="p">]</span>
</span><span id="__span-32-13"><a href="#__codelineno-32-13" id="__codelineno-32-13" name="__codelineno-32-13"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">"Generating joke..."</span><span class="p">)</span>
</span><span id="__span-32-14"><a href="#__codelineno-32-14" id="__codelineno-32-14" name="__codelineno-32-14"></a>    <span class="n">joke_response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">llm</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span>
</span><span id="__span-32-15"><a href="#__codelineno-32-15" id="__codelineno-32-15" name="__codelineno-32-15"></a>        <span class="p">[{</span><span class="s2">"role"</span><span class="p">:</span> <span class="s2">"user"</span><span class="p">,</span> <span class="s2">"content"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"Write a joke about </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">"</span><span class="p">}],</span>
</span><span id="__span-32-16"><a href="#__codelineno-32-16" id="__codelineno-32-16" name="__codelineno-32-16"></a><span class="hll">        <span class="n">config</span><span class="p">,</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-32-17"><a href="#__codelineno-32-17" id="__codelineno-32-17" name="__codelineno-32-17"></a>    <span class="p">)</span>
</span><span id="__span-32-18"><a href="#__codelineno-32-18" id="__codelineno-32-18" name="__codelineno-32-18"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="n">joke_response</span><span class="o">.</span><span class="n">content</span><span class="p">}</span>
</span><span id="__span-32-19"><a href="#__codelineno-32-19" id="__codelineno-32-19" name="__codelineno-32-19"></a>
</span><span id="__span-32-20"><a href="#__codelineno-32-20" id="__codelineno-32-20" name="__codelineno-32-20"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-32-21"><a href="#__codelineno-32-21" id="__codelineno-32-21" name="__codelineno-32-21"></a>    <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-32-22"><a href="#__codelineno-32-22" id="__codelineno-32-22" name="__codelineno-32-22"></a>    <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">call_model</span><span class="p">)</span>
</span><span id="__span-32-23"><a href="#__codelineno-32-23" id="__codelineno-32-23" name="__codelineno-32-23"></a>    <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"call_model"</span><span class="p">)</span>
</span><span id="__span-32-24"><a href="#__codelineno-32-24" id="__codelineno-32-24" name="__codelineno-32-24"></a>    <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-32-25"><a href="#__codelineno-32-25" id="__codelineno-32-25" name="__codelineno-32-25"></a><span class="p">)</span>
</span><span id="__span-32-26"><a href="#__codelineno-32-26" id="__codelineno-32-26" name="__codelineno-32-26"></a>
</span><span id="__span-32-27"><a href="#__codelineno-32-27" id="__codelineno-32-27" name="__codelineno-32-27"></a><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-32-28"><a href="#__codelineno-32-28" id="__codelineno-32-28" name="__codelineno-32-28"></a>    <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-32-29"><a href="#__codelineno-32-29" id="__codelineno-32-29" name="__codelineno-32-29"></a><span class="hll">    <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"messages"</span><span class="p">,</span> <span class="c1"># (3)!</span>
</span></span><span id="__span-32-30"><a href="#__codelineno-32-30" id="__codelineno-32-30" name="__codelineno-32-30"></a><span class="p">):</span>
</span><span id="__span-32-31"><a href="#__codelineno-32-31" id="__codelineno-32-31" name="__codelineno-32-31"></a>    <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
</span><span id="__span-32-32"><a href="#__codelineno-32-32" id="__codelineno-32-32" name="__codelineno-32-32"></a>        <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">"|"</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Accept <code>config</code> as an argument in the async node function.</li>
<li>Pass <code>config</code> to <code>llm.ainvoke()</code> to ensure proper context propagation.</li>
<li>Set <code>stream_mode="messages"</code> to stream LLM tokens.</li>
</ol>
</details>
<details class="example">
<summary>Extended example: async custom streaming with stream writer</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-33-1"><a href="#__codelineno-33-1" id="__codelineno-33-1" name="__codelineno-33-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypedDict</span>
</span><span id="__span-33-2"><a href="#__codelineno-33-2" id="__codelineno-33-2" name="__codelineno-33-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">langgraph.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">StreamWriter</span>
</span><span id="__span-33-3"><a href="#__codelineno-33-3" id="__codelineno-33-3" name="__codelineno-33-3"></a>
</span><span id="__span-33-4"><a href="#__codelineno-33-4" id="__codelineno-33-4" name="__codelineno-33-4"></a><span class="k">class</span><span class="w"> </span><span class="nc">State</span><span class="p">(</span><span class="n">TypedDict</span><span class="p">):</span>
</span><span id="__span-33-5"><a href="#__codelineno-33-5" id="__codelineno-33-5" name="__codelineno-33-5"></a>      <span class="n">topic</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-33-6"><a href="#__codelineno-33-6" id="__codelineno-33-6" name="__codelineno-33-6"></a>      <span class="n">joke</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-33-7"><a href="#__codelineno-33-7" id="__codelineno-33-7" name="__codelineno-33-7"></a>
</span><span id="__span-33-8"><a href="#__codelineno-33-8" id="__codelineno-33-8" name="__codelineno-33-8"></a><span class="hll"><span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">generate_joke</span><span class="p">(</span><span class="n">state</span><span class="p">:</span> <span class="n">State</span><span class="p">,</span> <span class="n">writer</span><span class="p">:</span> <span class="n">StreamWriter</span><span class="p">):</span> <span class="c1"># (1)!</span>
</span></span><span id="__span-33-9"><a href="#__codelineno-33-9" id="__codelineno-33-9" name="__codelineno-33-9"></a>      <span class="n">writer</span><span class="p">({</span><span class="s2">"custom_key"</span><span class="p">:</span> <span class="s2">"Streaming custom data while generating a joke"</span><span class="p">})</span>
</span><span id="__span-33-10"><a href="#__codelineno-33-10" id="__codelineno-33-10" name="__codelineno-33-10"></a>      <span class="k">return</span> <span class="p">{</span><span class="s2">"joke"</span><span class="p">:</span> <span class="sa">f</span><span class="s2">"This is a joke about </span><span class="si">{</span><span class="n">state</span><span class="p">[</span><span class="s1">'topic'</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">}</span>
</span><span id="__span-33-11"><a href="#__codelineno-33-11" id="__codelineno-33-11" name="__codelineno-33-11"></a>
</span><span id="__span-33-12"><a href="#__codelineno-33-12" id="__codelineno-33-12" name="__codelineno-33-12"></a><span class="n">graph</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-33-13"><a href="#__codelineno-33-13" id="__codelineno-33-13" name="__codelineno-33-13"></a>      <span class="n">StateGraph</span><span class="p">(</span><span class="n">State</span><span class="p">)</span>
</span><span id="__span-33-14"><a href="#__codelineno-33-14" id="__codelineno-33-14" name="__codelineno-33-14"></a>      <span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">generate_joke</span><span class="p">)</span>
</span><span id="__span-33-15"><a href="#__codelineno-33-15" id="__codelineno-33-15" name="__codelineno-33-15"></a>      <span class="o">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">START</span><span class="p">,</span> <span class="s2">"generate_joke"</span><span class="p">)</span>
</span><span id="__span-33-16"><a href="#__codelineno-33-16" id="__codelineno-33-16" name="__codelineno-33-16"></a>      <span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</span><span id="__span-33-17"><a href="#__codelineno-33-17" id="__codelineno-33-17" name="__codelineno-33-17"></a><span class="p">)</span>
</span><span id="__span-33-18"><a href="#__codelineno-33-18" id="__codelineno-33-18" name="__codelineno-33-18"></a>
</span><span id="__span-33-19"><a href="#__codelineno-33-19" id="__codelineno-33-19" name="__codelineno-33-19"></a><span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">astream</span><span class="p">(</span>
</span><span id="__span-33-20"><a href="#__codelineno-33-20" id="__codelineno-33-20" name="__codelineno-33-20"></a>      <span class="p">{</span><span class="s2">"topic"</span><span class="p">:</span> <span class="s2">"ice cream"</span><span class="p">},</span>
</span><span id="__span-33-21"><a href="#__codelineno-33-21" id="__codelineno-33-21" name="__codelineno-33-21"></a><span class="hll">      <span class="n">stream_mode</span><span class="o">=</span><span class="s2">"custom"</span><span class="p">,</span> <span class="c1"># (2)!</span>
</span></span><span id="__span-33-22"><a href="#__codelineno-33-22" id="__codelineno-33-22" name="__codelineno-33-22"></a><span class="p">):</span>
</span><span id="__span-33-23"><a href="#__codelineno-33-23" id="__codelineno-33-23" name="__codelineno-33-23"></a>      <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Add <code>writer</code> as an argument in the function signature of the async node or tool. LangGraph will automatically pass the stream writer to the function.</li>
<li>Set <code>stream_mode="custom"</code> to receive the custom data in the stream.</li>
</ol>
</details>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Overview" class="md-footer__link md-footer__link--prev" href="../../concepts/streaming/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                Overview
              </div>
</div>
</a>
<a aria-label="Next: Overview" class="md-footer__link md-footer__link--next" href="../../concepts/persistence/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                Overview
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2025 LangChain, Inc | <a href="#__consent">Consent Preferences</a>
</div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://langchain-ai.github.io/langgraphjs/" rel="noopener" target="_blank" title="langchain-ai.github.io">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M0 32v448h448V32zm243.8 349.4c0 43.6-25.6 63.5-62.9 63.5-33.7 0-53.2-17.4-63.2-38.5l34.3-20.7c6.6 11.7 12.6 21.6 27.1 21.6 13.8 0 22.6-5.4 22.6-26.5V237.7h42.1zm99.6 63.5c-39.1 0-64.4-18.6-76.7-43l34.3-19.8c9 14.7 20.8 25.6 41.5 25.6 17.4 0 28.6-8.7 28.6-20.8 0-14.4-11.4-19.5-30.7-28l-10.5-4.5c-30.4-12.9-50.5-29.2-50.5-63.5 0-31.6 24.1-55.6 61.6-55.6 26.8 0 46 9.3 59.8 33.7L368 290c-7.2-12.9-15-18-27.1-18-12.3 0-20.1 7.8-20.1 18 0 12.6 7.8 17.7 25.9 25.6l10.5 4.5c35.8 15.3 55.9 31 55.9 66.2 0 37.8-29.8 58.6-69.7 58.6"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/langchain-ai/langgraph" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/LangChainAI" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.action.edit", "content.tooltips", "navigation.indexes", "navigation.footer", "navigation.instant", "navigation.sections", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.tabs", "navigation.top", "navigation.prune", "navigation.tracking", "search.highlight", "search.share", "search.suggest"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
<script src="../../assets/javascripts/bundle.56ea9cef.min.js"></script>
</body>
</html>